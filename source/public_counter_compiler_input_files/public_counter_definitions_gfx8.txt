;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; Copyright (c) 2010-2018 Advanced Micro Devices, Inc. All rights reserved.
;;
;; Counter definitions for DX/VK/GL for Gfx8 (GFX IP v8)
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

name=GPUTime
desc=#Timing#Time this API command took to execute on the GPU in nanoseconds from the time the previous command reached the bottom of the pipeline (BOP) to the time this command reaches the bottom of the pipeline (BOP). Does not include time that draw calls are processed in parallel.
type=gpa_float64
usage=nanoseconds
[GLGfx8]
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
GPUTime_Bottom_To_Bottom_Duration
eqn=GPUTime_Bottom_To_Bottom_Duration,TS_FREQ,/,(1000000000),*

name=ExecutionDuration
desc=#Timing#GPU command execution duration in nanoseconds, from the time the command enters the top of the pipeline (TOP) to the time the command reaches the bottom of the pipeline (BOP). Does not include time that draw calls are processed in parallel.
type=gpa_float64
usage=nanoseconds
[DX12Gfx8]
[VKGfx8]
GPUTime_Top_To_Bottom_Duration
eqn=GPUTime_Top_To_Bottom_Duration,TS_FREQ,/,(1000000000),*

name=ExecutionStart
desc=#Timing#GPU command execution start time in nanoseconds. This is the time the command enters the top of the pipeline (TOP).
type=gpa_float64
usage=nanoseconds
[DX12Gfx8]
[VKGfx8]
GPUTime_Top_To_Bottom_Start
eqn=GPUTime_Top_To_Bottom_Start,TS_FREQ,/,(1000000000),*

name=ExecutionEnd
desc=#Timing#GPU command execution end time in nanoseconds. This is the time the command reaches the bottom of the pipeline (BOP).
type=gpa_float64
usage=nanoseconds
[DX12Gfx8]
[VKGfx8]
GPUTime_Top_To_Bottom_End
eqn=GPUTime_Top_To_Bottom_End,TS_FREQ,/,(1000000000),*

name=GPUBusy
usage=percentage
desc=#Timing#The percentage of time GPU was busy.
type=gpa_float64
[GLGfx8]
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
GRBM_PERF_SEL_GUI_ACTIVE
GRBM_PERF_SEL_COUNT
eqn=0,1,/,(100),*,(100),min

name=GPUBusyCycles
usage=cycles
desc=#Timing#Number of GPU cycles that the GPU was busy.
type=gpa_float64
[GLGfx8]
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0

name=TessellatorBusy
usage=percentage
desc=#Timing#The percentage of time the tessellation engine is busy.
type=gpa_float64
[GLGfx8]
VGT_PERF_VGT_TE11_BUSY
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,NUM_PRIM_PIPES,/,1,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
VGT*_PERF_VGT_TE11_BUSY[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,1,max,2,max,3,max,4,/,(100),*

name=TessellatorBusyCycles
usage=cycles
desc=#Timing#Number of GPU cycles that the tessellation engine is busy.
type=gpa_float64
[GLGfx8]
VGT_PERF_VGT_TE11_BUSY
eqn=0,NUM_PRIM_PIPES,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
VGT*_PERF_VGT_TE11_BUSY[0..3]
eqn=0,1,max,2,max,3,max

;; there are some quirks to the list of internal counters for these shader busy counters:
;; the PS_CTL_BUSY has been inserted into some of the earlier public counters because it
;; was being put into a second pass and causing results that were way higher (500%) than expected.
;; Since the PS is expected to be used often, I want that counter to report proper values
;; often. Doing this may cause some of the GS, HS, or CS counters to be split into a second pass
;; but I don't consider them to be quite as important.

name=VSBusy
desc=#Timing#The percentage of time the ShaderUnit has vertex shader work to do.
type=gpa_float64
usage=percentage
[GLGfx8]
SPI_PERF_VS_BUSY
SPI_PERF_ES_BUSY
SPI_PERF_LS_BUSY
SPI_PERF_PS_CTL_BUSY
SPI_PERF_VS_WAVE
SPI_PERF_ES_WAVE
SPI_PERF_LS_WAVE
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),0,4,ifnotzero,1,5,ifnotzero,2,6,ifnotzero,7,/,(100),*,(100),min
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SPI*_PERF_VS_BUSY[0..3]
SPI*_PERF_ES_BUSY[0..3]
SPI*_PERF_LS_BUSY[0..3]
SPI*_PERF_PS_CTL_BUSY[0..3]
SPI*_PERF_VS_WAVE[0..3]
SPI*_PERF_ES_WAVE[0..3]
SPI*_PERF_LS_WAVE[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),0,16,ifnotzero,4,20,ifnotzero,8,24,ifnotzero,(0),1,17,ifnotzero,5,21,ifnotzero,9,25,ifnotzero,max,(0),2,18,ifnotzero,6,22,ifnotzero,10,26,ifnotzero,max,(0),3,19,ifnotzero,7,23,ifnotzero,11,27,ifnotzero,max,28,/,(100),*,(100),min

name=VSBusyCycles
desc=#Timing#Number of GPU cycles that the ShaderUnit has vertex shader work to do.
type=gpa_float64
usage=cycles
[GLGfx8]
SPI_PERF_VS_BUSY
SPI_PERF_ES_BUSY
SPI_PERF_LS_BUSY
SPI_PERF_PS_CTL_BUSY
SPI_PERF_VS_WAVE
SPI_PERF_ES_WAVE
SPI_PERF_LS_WAVE
eqn=(0),0,4,ifnotzero,1,5,ifnotzero,2,6,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SPI*_PERF_VS_BUSY[0..3]
SPI*_PERF_ES_BUSY[0..3]
SPI*_PERF_LS_BUSY[0..3]
SPI*_PERF_PS_CTL_BUSY[0..3]
SPI*_PERF_VS_WAVE[0..3]
SPI*_PERF_ES_WAVE[0..3]
SPI*_PERF_LS_WAVE[0..3]
eqn=(0),0,16,ifnotzero,4,20,ifnotzero,8,24,ifnotzero,(0),1,17,ifnotzero,5,21,ifnotzero,9,25,ifnotzero,max,(0),2,18,ifnotzero,6,22,ifnotzero,10,26,ifnotzero,max,(0),3,19,ifnotzero,7,23,ifnotzero,11,27,ifnotzero,max

name=VSTime
desc=#Timing#Time vertex shaders are busy in nanoseconds.
type=gpa_float64
usage=nanoseconds
[GLGfx8]
GPUTime_Bottom_To_Bottom_Duration
SPI_PERF_VS_BUSY
SPI_PERF_ES_BUSY
SPI_PERF_LS_BUSY
SPI_PERF_PS_CTL_BUSY
SPI_PERF_VS_WAVE
SPI_PERF_ES_WAVE
SPI_PERF_LS_WAVE
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),1,5,ifnotzero,2,6,ifnotzero,3,7,ifnotzero,8,/,(1),min,GPUTime_Bottom_To_Bottom_Duration,TS_FREQ,/,(1000000000),*,*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
GPUTime_Bottom_To_Bottom_Duration
SPI*_PERF_VS_BUSY[0..3]
SPI*_PERF_ES_BUSY[0..3]
SPI*_PERF_LS_BUSY[0..3]
SPI*_PERF_PS_CTL_BUSY[0..3]
SPI*_PERF_VS_WAVE[0..3]
SPI*_PERF_ES_WAVE[0..3]
SPI*_PERF_LS_WAVE[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),1,17,ifnotzero,5,21,ifnotzero,9,25,ifnotzero,(0),2,18,ifnotzero,6,22,ifnotzero,10,26,ifnotzero,max,(0),3,19,ifnotzero,7,23,ifnotzero,11,27,ifnotzero,max,(0),4,20,ifnotzero,8,24,ifnotzero,12,28,ifnotzero,max,29,/,(1),min,GPUTime_Bottom_To_Bottom_Duration,TS_FREQ,/,(1000000000),*,*

name=HSBusy
desc=#Timing#The percentage of time the ShaderUnit has hull shader work to do.
type=gpa_float64
usage=percentage
[GLGfx8]
SPI_PERF_HS_BUSY
SPI_PERF_HS_WAVE
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),0,1,ifnotzero,2,/,(100),*,(100),min
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SPI*_PERF_HS_BUSY[0..3]
SPI*_PERF_HS_WAVE[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),0,4,ifnotzero,(0),1,5,ifnotzero,max,(0),2,6,ifnotzero,max,(0),3,7,ifnotzero,max,8,/,(100),*,(100),min

name=HSBusyCycles
desc=#Timing#Number of GPU cycles that the ShaderUnit has hull shader work to do.
type=gpa_float64
usage=cycles
[GLGfx8]
SPI_PERF_HS_BUSY
SPI_PERF_HS_WAVE
eqn=(0),0,1,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SPI*_PERF_HS_BUSY[0..3]
SPI*_PERF_HS_WAVE[0..3]
eqn=(0),0,4,ifnotzero,(0),1,5,ifnotzero,max,(0),2,6,ifnotzero,max,(0),3,7,ifnotzero,max

name=HSTime
desc=#Timing#Time hull shaders are busy in nanoseconds.
type=gpa_float64
usage=nanoseconds
[GLGfx8]
GPUTime_Bottom_To_Bottom_Duration
SPI_PERF_HS_BUSY
SPI_PERF_HS_WAVE
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),1,2,ifnotzero,3,/,(1),min,GPUTime_Bottom_To_Bottom_Duration,TS_FREQ,/,(1000000000),*,*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
GPUTime_Bottom_To_Bottom_Duration
SPI*_PERF_HS_BUSY[0..3]
SPI*_PERF_HS_WAVE[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),1,5,ifnotzero,(0),2,6,ifnotzero,max,(0),3,7,ifnotzero,max,(0),4,8,ifnotzero,max,9,/,(1),min,GPUTime_Bottom_To_Bottom_Duration,TS_FREQ,/,(1000000000),*,*


name=DSBusy
desc=#Timing#The percentage of time the ShaderUnit has domain shader work to do.
type=gpa_float64
usage=percentage
[GLGfx8]
SPI_PERF_VS_BUSY
SPI_PERF_ES_BUSY
SPI_PERF_PS_CTL_BUSY
SPI_PERF_ES_WAVE
SPI_PERF_LS_WAVE
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),0,1,3,ifnotzero,4,ifnotzero,5,/,(100),*,(100),min
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SPI*_PERF_VS_BUSY[0..3]
SPI*_PERF_ES_BUSY[0..3]
SPI*_PERF_PS_CTL_BUSY[0..3]
SPI*_PERF_ES_WAVE[0..3]
SPI*_PERF_LS_WAVE[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),0,4,12,ifnotzero,16,ifnotzero,(0),1,5,13,ifnotzero,17,ifnotzero,max,(0),2,6,14,ifnotzero,18,ifnotzero,max,(0),3,7,15,ifnotzero,19,ifnotzero,max,20,/,(100),*,(100),min

name=DSBusyCycles
desc=#Timing#Number of GPU cycles that the ShaderUnit has domain shader work to do.
type=gpa_float64
usage=cycles
[GLGfx8]
SPI_PERF_VS_BUSY
SPI_PERF_ES_BUSY
SPI_PERF_PS_CTL_BUSY
SPI_PERF_ES_WAVE
SPI_PERF_LS_WAVE
eqn=(0),0,1,3,ifnotzero,4,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SPI*_PERF_VS_BUSY[0..3]
SPI*_PERF_ES_BUSY[0..3]
SPI*_PERF_PS_CTL_BUSY[0..3]
SPI*_PERF_ES_WAVE[0..3]
SPI*_PERF_LS_WAVE[0..3]
eqn=(0),0,4,12,ifnotzero,16,ifnotzero,(0),1,5,13,ifnotzero,17,ifnotzero,max,(0),2,6,14,ifnotzero,18,ifnotzero,max,(0),3,7,15,ifnotzero,19,ifnotzero,max

name=DSTime
desc=#Timing#Time domain shaders are busy in nanoseconds.
type=gpa_float64
usage=nanoseconds
[GLGfx8]
GPUTime_Bottom_To_Bottom_Duration
SPI_PERF_VS_BUSY
SPI_PERF_ES_BUSY
SPI_PERF_PS_CTL_BUSY
SPI_PERF_ES_WAVE
SPI_PERF_LS_WAVE
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),1,2,4,ifnotzero,5,ifnotzero,6,/,(1),min,GPUTime_Bottom_To_Bottom_Duration,TS_FREQ,/,(1000000000),*,*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
GPUTime_Bottom_To_Bottom_Duration
SPI*_PERF_VS_BUSY[0..3]
SPI*_PERF_ES_BUSY[0..3]
SPI*_PERF_PS_CTL_BUSY[0..3]
SPI*_PERF_ES_WAVE[0..3]
SPI*_PERF_LS_WAVE[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),1,5,13,ifnotzero,17,ifnotzero,(0),2,6,14,ifnotzero,18,ifnotzero,max,(0),3,7,15,ifnotzero,19,ifnotzero,max,(0),4,8,16,ifnotzero,20,ifnotzero,max,21,/,(1),min,GPUTime_Bottom_To_Bottom_Duration,TS_FREQ,/,(1000000000),*,*

name=GSBusy
desc=#Timing#The percentage of time the ShaderUnit has geometry shader work to do.
type=gpa_float64
usage=percentage
[GLGfx8]
SPI_PERF_GS_BUSY
SPI_PERF_GS_WAVE
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),0,1,ifnotzero,2,/,(100),*,(100),min
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SPI*_PERF_GS_BUSY[0..3]
SPI*_PERF_GS_WAVE[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),0,4,ifnotzero,(0),1,5,ifnotzero,max,(0),2,6,ifnotzero,max,(0),3,7,ifnotzero,max,8,/,(100),*,(100),min

name=GSBusyCycles
desc=#Timing#Number of GPU cycles that the ShaderUnit has geometry shader work to do.
type=gpa_float64
usage=cycles
[GLGfx8]
SPI_PERF_GS_BUSY
SPI_PERF_GS_WAVE
eqn=(0),0,1,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SPI*_PERF_GS_BUSY[0..3]
SPI*_PERF_GS_WAVE[0..3]
eqn=(0),0,4,ifnotzero,(0),1,5,ifnotzero,max,(0),2,6,ifnotzero,max,(0),3,7,ifnotzero,max

name=GSTime
desc=#Timing#Time geometry shaders are busy in nanoseconds.
type=gpa_float64
usage=nanoseconds
[GLGfx8]
GPUTime_Bottom_To_Bottom_Duration
SPI_PERF_GS_BUSY
SPI_PERF_GS_WAVE
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),1,2,ifnotzero,3,/,(1),min,GPUTime_Bottom_To_Bottom_Duration,TS_FREQ,/,(1000000000),*,*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
GPUTime_Bottom_To_Bottom_Duration
SPI*_PERF_GS_BUSY[0..3]
SPI*_PERF_GS_WAVE[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),1,5,ifnotzero,(0),2,6,ifnotzero,max,(0),3,7,ifnotzero,max,(0),4,8,ifnotzero,max,9,/,(1),min,GPUTime_Bottom_To_Bottom_Duration,TS_FREQ,/,(1000000000),*,*

name=PSBusy
desc=#Timing#The percentage of time the ShaderUnit has pixel shader work to do.
type=gpa_float64
usage=percentage
[GLGfx8]
SPI_PERF_PS_CTL_BUSY
SPI_PERF_PS_CTL_WAVE
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),0,1,ifnotzero,2,/,(100),*,(100),min
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SPI*_PERF_PS_CTL_BUSY[0..3]
SPI*_PERF_PS_CTL_WAVE[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),0,4,ifnotzero,(0),1,5,ifnotzero,max,(0),2,6,ifnotzero,max,(0),3,7,ifnotzero,max,8,/,(100),*

name=PSBusyCycles
desc=#Timing#Number of GPU cycles that the ShaderUnit has pixel shader work to do.
type=gpa_float64
usage=cycles
[GLGfx8]
SPI_PERF_PS_CTL_BUSY
SPI_PERF_PS_CTL_WAVE
eqn=(0),0,1,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SPI*_PERF_PS_CTL_BUSY[0..3]
SPI*_PERF_PS_CTL_WAVE[0..3]
eqn=(0),0,4,ifnotzero,(0),1,5,ifnotzero,max,(0),2,6,ifnotzero,max,(0),3,7,ifnotzero,max

name=PSTime
desc=#Timing#Time pixel shaders are busy in nanoseconds.
type=gpa_float64
usage=nanoseconds
[GLGfx8]
GPUTime_Bottom_To_Bottom_Duration
SPI_PERF_PS_CTL_BUSY
SPI_PERF_PS_CTL_WAVE
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),1,2,ifnotzero,3,/,(1),min,GPUTime_Bottom_To_Bottom_Duration,TS_FREQ,/,(1000000000),*,*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
GPUTime_Bottom_To_Bottom_Duration
SPI*_PERF_PS_CTL_BUSY[0..3]
SPI*_PERF_PS_CTL_WAVE[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),1,5,ifnotzero,(0),2,6,ifnotzero,max,(0),3,7,ifnotzero,max,(0),4,8,ifnotzero,max,9,/,GPUTime_Bottom_To_Bottom_Duration,TS_FREQ,/,(1000000000),*,*

name=CSBusy
desc=#Timing#The percentage of time the ShaderUnit has compute shader work to do.
type=gpa_float64
usage=percentage
[GLGfx8]
SPI_PERF_CSG_BUSY
SPI_PERF_CSG_WAVE
SPI_PERF_CSN_BUSY
SPI_PERF_CSN_WAVE
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),0,1,ifnotzero,(0),2,3,ifnotzero,max,4,/,(100),*,(100),min
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SPI*_PERF_CSG_BUSY[0..3]
SPI*_PERF_CSG_WAVE[0..3]
SPI*_PERF_CSN_BUSY[0..3]
SPI*_PERF_CSN_WAVE[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=SPI*_PERF_CSG_BUSY,SPI*_PERF_CSG_WAVE,comparemax4,SPI*_PERF_CSN_BUSY,SPI*_PERF_CSN_WAVE,comparemax4,max,GRBM_PERF_SEL_GUI_ACTIVE,/,(100),*,(100),min

name=CSBusyCycles
desc=#Timing#Number of GPU cycles that the ShaderUnit has compute shader work to do.
type=gpa_float64
usage=cycles
[GLGfx8]
SPI_PERF_CSG_BUSY
SPI_PERF_CSG_WAVE
SPI_PERF_CSN_BUSY
SPI_PERF_CSN_WAVE
eqn=(0),0,1,ifnotzero,(0),2,3,ifnotzero,max
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SPI*_PERF_CSG_BUSY[0..3]
SPI*_PERF_CSG_WAVE[0..3]
SPI*_PERF_CSN_BUSY[0..3]
SPI*_PERF_CSN_WAVE[0..3]
eqn=SPI*_PERF_CSG_BUSY,SPI*_PERF_CSG_WAVE,comparemax4,SPI*_PERF_CSN_BUSY,SPI*_PERF_CSN_WAVE,comparemax4,max

name=CSTime
desc=#Timing#Time compute shaders are busy in nanoseconds.
type=gpa_float64
usage=nanoseconds
[GLGfx8]
GPUTime_Bottom_To_Bottom_Duration
SPI_PERF_CSG_BUSY
SPI_PERF_CSG_WAVE
SPI_PERF_CSN_BUSY
SPI_PERF_CSN_WAVE
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),1,2,ifnotzero,(0),3,4,ifnotzero,max,5,/,(1),min,GPUTime_Bottom_To_Bottom_Duration,TS_FREQ,/,(1000000000),*,*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
GPUTime_Bottom_To_Bottom_Duration
SPI*_PERF_CSG_BUSY[0..3]
SPI*_PERF_CSG_WAVE[0..3]
SPI*_PERF_CSN_BUSY[0..3]
SPI*_PERF_CSN_WAVE[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=SPI*_PERF_CSG_BUSY,SPI*_PERF_CSG_WAVE,comparemax4,SPI*_PERF_CSN_BUSY,SPI*_PERF_CSN_WAVE,comparemax4,max,GRBM_PERF_SEL_GUI_ACTIVE,/,(1),min,GPUTime_Bottom_To_Bottom_Duration,TS_FREQ,/,(1000000000),*,*

name=VSVerticesIn
desc=#VertexShader#The number of vertices processed by the VS.
type=gpa_float64
usage=items
[GLGfx8]
VGT_PERF_VGT_SPI_VSVERT_SEND
VGT_PERF_VGT_SPI_ESVERT_VALID
VGT_PERF_VGT_SPI_LSVERT_VALID
eqn=0,1,1,ifnotzero,2,2,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
VGT*_PERF_VGT_SPI_VSVERT_SEND[0..3]
VGT*_PERF_VGT_SPI_ESVERT_VALID[0..3]
VGT*_PERF_VGT_SPI_LSVERT_VALID[0..3]
eqn=0..3,sum4,4..7,sum4,4..7,sum4,ifnotzero,8..11,sum4,8..11,sum4,ifnotzero

name=VSVALUInstCount
desc=#VertexShader#Average number of vector ALU instructions executed in the VS. Affected by flow control.
type=gpa_float64
usage=items
[GLGfx8]
SQ_VS_PERF_SEL_INSTS_VALU
SQ_VS_PERF_SEL_WAVES
SQ_ES_PERF_SEL_INSTS_VALU
SQ_ES_PERF_SEL_WAVES
SQ_ES_PERF_SEL_ITEMS
SQ_LS_PERF_SEL_INSTS_VALU
SQ_LS_PERF_SEL_WAVES
SQ_LS_PERF_SEL_ITEMS
eqn=0,1,/,2,3,/,4,ifnotzero,5,6,/,7,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_VS*_PERF_SEL_INSTS_VALU[0..3]
SQ_VS*_PERF_SEL_WAVES[0..3]
SQ_ES*_PERF_SEL_INSTS_VALU[0..3]
SQ_ES*_PERF_SEL_WAVES[0..3]
SQ_ES*_PERF_SEL_ITEMS[0..3]
SQ_LS*_PERF_SEL_INSTS_VALU[0..3]
SQ_LS*_PERF_SEL_WAVES[0..3]
SQ_LS*_PERF_SEL_ITEMS[0..3]
eqn=0..3,sum4,4..7,sum4,/,8..11,sum4,12..15,sum4,/,16..19,sum4,ifnotzero,20..23,sum4,24..27,sum4,/,28..31,sum4,ifnotzero

name=VSSALUInstCount
desc=#VertexShader#Average number of scalar ALU instructions executed in the VS. Affected by flow control.
type=gpa_float64
usage=items
[GLGfx8]
SQ_VS_PERF_SEL_INSTS_SALU
SQ_VS_PERF_SEL_WAVES
SQ_ES_PERF_SEL_INSTS_SALU
SQ_ES_PERF_SEL_WAVES
SQ_ES_PERF_SEL_ITEMS
SQ_LS_PERF_SEL_INSTS_SALU
SQ_LS_PERF_SEL_WAVES
SQ_LS_PERF_SEL_ITEMS
eqn=0,1,/,2,3,/,4,ifnotzero,5,6,/,7,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_VS*_PERF_SEL_INSTS_SALU[0..3]
SQ_VS*_PERF_SEL_WAVES[0..3]
SQ_ES*_PERF_SEL_INSTS_SALU[0..3]
SQ_ES*_PERF_SEL_WAVES[0..3]
SQ_ES*_PERF_SEL_ITEMS[0..3]
SQ_LS*_PERF_SEL_INSTS_SALU[0..3]
SQ_LS*_PERF_SEL_WAVES[0..3]
SQ_LS*_PERF_SEL_ITEMS[0..3]
eqn=0..3,sum4,4..7,sum4,/,8..11,sum4,12..15,sum4,/,16..19,sum4,ifnotzero,20..23,sum4,24..27,sum4,/,28..31,sum4,ifnotzero

name=VSVALUBusy
desc=#VertexShader#The percentage of GPUTime vector ALU instructions are being processed by the VS.
type=gpa_float64
usage=percentage
[GLGfx8]
SQ_VS_PERF_SEL_INST_CYCLES_VALU
SQ_ES_PERF_SEL_INST_CYCLES_VALU
SQ_ES_PERF_SEL_ITEMS
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,1,2,ifnotzero,(4),*,NUM_SIMDS,/,3,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_VS*_PERF_SEL_INST_CYCLES_VALU[0..3]
SQ_ES*_PERF_SEL_INST_CYCLES_VALU[0..3]
SQ_ES*_PERF_SEL_ITEMS[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
SQ_LS*_PERF_SEL_INST_CYCLES_VALU[0..3]
SQ_LS*_PERF_SEL_ITEMS[0..3]
eqn=0..3,sum4,4..7,sum4,8..11,sum4,ifnotzero,13..16,sum4,17..20,sum4,ifnotzero,(4),*,NUM_SIMDS,/,12,/,(100),*

name=VSVALUBusyCycles
desc=#VertexShader#Number of GPU cycles where vector ALU instructions are being processed by the VS.
type=gpa_float64
usage=cycles
[GLGfx8]
SQ_VS_PERF_SEL_INST_CYCLES_VALU
SQ_ES_PERF_SEL_INST_CYCLES_VALU
SQ_ES_PERF_SEL_ITEMS
eqn=0,1,2,ifnotzero,(4),*,NUM_SIMDS,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_VS*_PERF_SEL_INST_CYCLES_VALU[0..3]
SQ_ES*_PERF_SEL_INST_CYCLES_VALU[0..3]
SQ_ES*_PERF_SEL_ITEMS[0..3]
SQ_LS*_PERF_SEL_INST_CYCLES_VALU[0..3]
SQ_LS*_PERF_SEL_ITEMS[0..3]
eqn=0..3,sum4,4..7,sum4,8..11,sum4,ifnotzero,12..15,sum4,16..19,sum4,ifnotzero,(4),*,NUM_SIMDS,/

name=VSSALUBusy
desc=#VertexShader#The percentage of GPUTime scalar ALU instructions are being processed by the VS.
type=gpa_float64
usage=percentage
[GLGfx8]
SQ_VS_PERF_SEL_INST_CYCLES_SALU
SQ_ES_PERF_SEL_INST_CYCLES_SALU
SQ_ES_PERF_SEL_ITEMS
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,1,2,ifnotzero,NUM_CUS,/,3,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_VS*_PERF_SEL_INST_CYCLES_SALU[0..3]
SQ_ES*_PERF_SEL_INST_CYCLES_SALU[0..3]
SQ_ES*_PERF_SEL_ITEMS[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
SQ_LS*_PERF_SEL_INST_CYCLES_SALU[0..3]
SQ_LS*_PERF_SEL_ITEMS[0..3]
eqn=0..3,sum4,4..7,sum4,8..11,sum4,ifnotzero,13..16,sum4,17..20,sum4,ifnotzero,NUM_CUS,/,12,/,(100),*

name=VSSALUBusyCycles
desc=#VertexShader#Number of GPU cycles where scalar ALU instructions are being processed by the VS.
type=gpa_float64
usage=cycles
[GLGfx8]
SQ_VS_PERF_SEL_INST_CYCLES_SALU
SQ_ES_PERF_SEL_INST_CYCLES_SALU
SQ_ES_PERF_SEL_ITEMS
eqn=0,1,2,ifnotzero,NUM_CUS,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_VS*_PERF_SEL_INST_CYCLES_SALU[0..3]
SQ_ES*_PERF_SEL_INST_CYCLES_SALU[0..3]
SQ_ES*_PERF_SEL_ITEMS[0..3]
SQ_LS*_PERF_SEL_INST_CYCLES_SALU[0..3]
SQ_LS*_PERF_SEL_ITEMS[0..3]
eqn=0..3,sum4,4..7,sum4,8..11,sum4,ifnotzero,12..15,sum4,16..19,sum4,ifnotzero,NUM_CUS,/

name=HSPatches
desc=#HullShader#The number of patches processed by the HS.
type=gpa_float64
usage=items
[GLGfx8]
VGT_PERF_VGT_SPI_HSVERT_VALID
eqn=0
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
VGT*_PERF_VGT_SPI_HSVERT_VALID[0..3]
eqn=0..3,sum4

name=HSVALUInstCount
desc=#HullShader#Average number of vector ALU instructions executed in the HS. Affected by flow control.
type=gpa_float64
usage=items
[GLGfx8]
SQ_HS_PERF_SEL_INSTS_VALU
SQ_HS_PERF_SEL_WAVES
eqn=0,1,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_HS*_PERF_SEL_INSTS_VALU[0..3]
SQ_HS*_PERF_SEL_WAVES[0..3]
eqn=0..3,sum4,4..7,sum4,/

name=HSSALUInstCount
desc=#HullShader#Average number of scalar ALU instructions executed in the HS. Affected by flow control.
type=gpa_float64
usage=items
[GLGfx8]
SQ_HS_PERF_SEL_INSTS_SALU
SQ_HS_PERF_SEL_WAVES
eqn=0,1,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_HS*_PERF_SEL_INSTS_SALU[0..3]
SQ_HS*_PERF_SEL_WAVES[0..3]
eqn=0..3,sum4,4..7,sum4,/

name=HSVALUBusy
desc=#HullShader#The percentage of GPUTime vector ALU instructions are being processed by the HS.
type=gpa_float64
usage=percentage
[GLGfx8]
SQ_HS_PERF_SEL_INST_CYCLES_VALU
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,(4),*,NUM_SIMDS,/,1,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_HS*_PERF_SEL_INST_CYCLES_VALU[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0..3,sum4,(4),*,NUM_SIMDS,/,4,/,(100),*

name=HSVALUBusyCycles
desc=#HullShader#Number of GPU cycles vector where ALU instructions are being processed by the HS.
type=gpa_float64
usage=cycles
[GLGfx8]
SQ_HS_PERF_SEL_INST_CYCLES_VALU
eqn=0,(4),*,NUM_SIMDS,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_HS*_PERF_SEL_INST_CYCLES_VALU[0..3]
eqn=0..3,sum4,(4),*,NUM_SIMDS,/

name=HSSALUBusy
desc=#HullShader#The percentage of GPUTime scalar ALU instructions are being processed by the HS.
type=gpa_float64
usage=percentage
[GLGfx8]
SQ_HS_PERF_SEL_INST_CYCLES_SALU
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,NUM_CUS,/,1,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_HS*_PERF_SEL_INST_CYCLES_SALU[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0..3,sum4,NUM_CUS,/,4,/,(100),*

name=HSSALUBusyCycles
desc=#HullShader#Number of GPU cycles where scalar ALU instructions are being processed by the HS.
type=gpa_float64
usage=cycles
[GLGfx8]
SQ_HS_PERF_SEL_INST_CYCLES_SALU
eqn=0,NUM_CUS,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_HS*_PERF_SEL_INST_CYCLES_SALU[0..3]
eqn=0..3,sum4,NUM_CUS,/

name=DSVerticesIn
desc=#DomainShader#The number of vertices processed by the DS.
type=gpa_float64
usage=items
[GLGfx8]
VGT_PERF_VGT_SPI_VSVERT_SEND
VGT_PERF_VGT_SPI_ESVERT_VALID
VGT_PERF_VGT_SPI_LSVERT_VALID
eqn=(0),0,1,1,ifnotzero,2,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
VGT*_PERF_VGT_SPI_VSVERT_SEND[0..3]
VGT*_PERF_VGT_SPI_ESVERT_VALID[0..3]
VGT*_PERF_VGT_SPI_LSVERT_VALID[0..3]
eqn=(0),0..3,sum4,4..7,sum4,4..7,sum4,ifnotzero,8..11,sum4,ifnotzero

name=DSVALUInstCount
desc=#DomainShader#Average number of vector ALU instructions executed in the DS. Affected by flow control.
type=gpa_float64
usage=items
[GLGfx8]
SQ_VS_PERF_SEL_INSTS_VALU
SQ_VS_PERF_SEL_WAVES
SQ_ES_PERF_SEL_INSTS_VALU
SQ_ES_PERF_SEL_WAVES
SQ_ES_PERF_SEL_ITEMS
SQ_LS_PERF_SEL_ITEMS
eqn=(0),0,1,/,2,3,/,4,ifnotzero,5,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_VS*_PERF_SEL_INSTS_VALU[0..3]
SQ_VS*_PERF_SEL_WAVES[0..3]
SQ_ES*_PERF_SEL_INSTS_VALU[0..3]
SQ_ES*_PERF_SEL_WAVES[0..3]
SQ_ES*_PERF_SEL_ITEMS[0..3]
SQ_LS*_PERF_SEL_ITEMS[0..3]
eqn=(0),0..3,sum4,4..7,sum4,/,8..11,sum4,12..15,sum4,/,16..19,sum4,ifnotzero,20..23,sum4,ifnotzero

name=DSSALUInstCount
desc=#DomainShader#Average number of scalar ALU instructions executed in the DS. Affected by flow control.
type=gpa_float64
usage=items
[GLGfx8]
SQ_VS_PERF_SEL_INSTS_SALU
SQ_VS_PERF_SEL_WAVES
SQ_ES_PERF_SEL_INSTS_SALU
SQ_ES_PERF_SEL_WAVES
SQ_ES_PERF_SEL_ITEMS
SQ_LS_PERF_SEL_ITEMS
eqn=(0),0,1,/,2,3,/,4,ifnotzero,5,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_VS*_PERF_SEL_INSTS_SALU[0..3]
SQ_VS*_PERF_SEL_WAVES[0..3]
SQ_ES*_PERF_SEL_INSTS_SALU[0..3]
SQ_ES*_PERF_SEL_WAVES[0..3]
SQ_ES*_PERF_SEL_ITEMS[0..3]
SQ_LS*_PERF_SEL_ITEMS[0..3]
eqn=(0),0..3,sum4,4..7,sum4,/,8..11,sum4,12..15,sum4,/,16..19,sum4,ifnotzero,20..23,sum4,ifnotzero

name=DSVALUBusy
desc=#DomainShader#The percentage of GPUTime vector ALU instructions are being processed by the DS.
type=gpa_float64
usage=percentage
[GLGfx8]
SQ_VS_PERF_SEL_INST_CYCLES_VALU
SQ_ES_PERF_SEL_INST_CYCLES_VALU
GRBM_PERF_SEL_GUI_ACTIVE
SQ_ES_PERF_SEL_ITEMS
SQ_LS_PERF_SEL_ITEMS
eqn=(0),0,1,3,ifnotzero,4,ifnotzero,(4),*,NUM_SIMDS,/,2,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_VS*_PERF_SEL_INST_CYCLES_VALU[0..3]
SQ_ES*_PERF_SEL_INST_CYCLES_VALU[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
SQ_ES*_PERF_SEL_ITEMS[0..3]
SQ_LS*_PERF_SEL_ITEMS[0..3]
eqn=(0),0..3,sum4,4..7,sum4,9..12,sum4,ifnotzero,13..16,sum4,ifnotzero,(4),*,NUM_SIMDS,/,8,/,(100),*

name=DSVALUBusyCycles
desc=#DomainShader#Number of GPU cycles where vector ALU instructions are being processed by the DS.
type=gpa_float64
usage=cycles
[GLGfx8]
SQ_VS_PERF_SEL_INST_CYCLES_VALU
SQ_ES_PERF_SEL_INST_CYCLES_VALU
SQ_ES_PERF_SEL_ITEMS
SQ_LS_PERF_SEL_ITEMS
eqn=(0),0,1,2,ifnotzero,3,ifnotzero,(4),*,NUM_SIMDS,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_VS*_PERF_SEL_INST_CYCLES_VALU[0..3]
SQ_ES*_PERF_SEL_INST_CYCLES_VALU[0..3]
SQ_ES*_PERF_SEL_ITEMS[0..3]
SQ_LS*_PERF_SEL_ITEMS[0..3]
eqn=(0),0..3,sum4,4..7,sum4,8..11,sum4,ifnotzero,12..15,sum4,ifnotzero,(4),*,NUM_SIMDS,/

name=DSSALUBusy
desc=#DomainShader#The percentage of GPUTime scalar ALU instructions are being processed by the DS.
type=gpa_float64
usage=percentage
[GLGfx8]
SQ_VS_PERF_SEL_INST_CYCLES_SALU
SQ_ES_PERF_SEL_INST_CYCLES_SALU
GRBM_PERF_SEL_GUI_ACTIVE
SQ_ES_PERF_SEL_ITEMS
SQ_LS_PERF_SEL_ITEMS
eqn=(0),0,1,3,ifnotzero,4,ifnotzero,NUM_CUS,/,2,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_VS*_PERF_SEL_INST_CYCLES_SALU[0..3]
SQ_ES*_PERF_SEL_INST_CYCLES_SALU[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
SQ_ES*_PERF_SEL_ITEMS[0..3]
SQ_LS*_PERF_SEL_ITEMS[0..3]
eqn=(0),0..3,sum4,4..7,sum4,9..12,sum4,ifnotzero,13..16,sum4,ifnotzero,NUM_CUS,/,8,/,(100),*

name=DSSALUBusyCycles
desc=#DomainShader#Number of GPU cycles where scalar ALU instructions are being processed by the DS.
type=gpa_float64
usage=cycles
[GLGfx8]
SQ_VS_PERF_SEL_INST_CYCLES_SALU
SQ_ES_PERF_SEL_INST_CYCLES_SALU
SQ_ES_PERF_SEL_ITEMS
SQ_LS_PERF_SEL_ITEMS
eqn=(0),0,1,2,ifnotzero,3,ifnotzero,NUM_CUS,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_VS*_PERF_SEL_INST_CYCLES_SALU[0..3]
SQ_ES*_PERF_SEL_INST_CYCLES_SALU[0..3]
SQ_ES*_PERF_SEL_ITEMS[0..3]
SQ_LS*_PERF_SEL_ITEMS[0..3]
eqn=(0),0..3,sum4,4..7,sum4,8..11,sum4,ifnotzero,12..15,sum4,ifnotzero,NUM_CUS,/

name=GSPrimsIn
desc=#GeometryShader#The number of primitives passed into the GS.
type=gpa_float64
usage=items
[GLGfx8]
VGT_PERF_VGT_SPI_GSPRIM_VALID
eqn=0
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
VGT*_PERF_VGT_SPI_GSPRIM_VALID[0..3]
eqn=0..3,sum4

name=GSVerticesOut
desc=#GeometryShader#The number of vertices output by the GS.
type=gpa_float64
usage=items
[GLGfx8]
VGT_PERF_VGT_SPI_VSVERT_SEND
VGT_PERF_VGT_SPI_ESVERT_VALID
eqn=(0),0,1,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
VGT*_PERF_VGT_SPI_VSVERT_SEND[0..3]
VGT*_PERF_VGT_SPI_ESVERT_VALID[0..3]
eqn=(0),0..3,sum4,4..7,sum4,ifnotzero

name=GSVALUInstCount
desc=#GeometryShader#Average number of vector ALU instructions executed in the GS. Affected by flow control.
type=gpa_float64
usage=items
[GLGfx8]
SQ_GS_PERF_SEL_INSTS_VALU
SQ_GS_PERF_SEL_WAVES
eqn=0,1,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_GS*_PERF_SEL_INSTS_VALU[0..3]
SQ_GS*_PERF_SEL_WAVES[0..3]
eqn=0..3,sum4,4..7,sum4,/

name=GSSALUInstCount
desc=#GeometryShader#Average number of scalar ALU instructions executed in the GS. Affected by flow control.
type=gpa_float64
usage=items
[GLGfx8]
SQ_GS_PERF_SEL_INSTS_SALU
SQ_GS_PERF_SEL_WAVES
eqn=0,1,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_GS*_PERF_SEL_INSTS_SALU[0..3]
SQ_GS*_PERF_SEL_WAVES[0..3]
eqn=0..3,sum4,4..7,sum4,/

name=GSVALUBusy
desc=#GeometryShader#The percentage of GPUTime vector ALU instructions are being processed by the GS.
type=gpa_float64
usage=percentage
[GLGfx8]
SQ_GS_PERF_SEL_INST_CYCLES_VALU
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,(4),*,NUM_SIMDS,/,1,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_GS*_PERF_SEL_INST_CYCLES_VALU[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0..3,sum4,(4),*,NUM_SIMDS,/,4,/,(100),*

name=GSVALUBusyCycles
desc=#GeometryShader#Number of GPU cycles where vector ALU instructions are being processed by the GS.
type=gpa_float64
usage=cycles
[GLGfx8]
SQ_GS_PERF_SEL_INST_CYCLES_VALU
eqn=0,(4),*,NUM_SIMDS,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_GS*_PERF_SEL_INST_CYCLES_VALU[0..3]
eqn=0..3,sum4,(4),*,NUM_SIMDS,/

name=GSSALUBusy
desc=#GeometryShader#The percentage of GPUTime scalar ALU instructions are being processed by the GS.
type=gpa_float64
usage=percentage
[GLGfx8]
SQ_GS_PERF_SEL_INST_CYCLES_SALU
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,NUM_CUS,/,1,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_GS*_PERF_SEL_INST_CYCLES_SALU[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0..3,sum4,NUM_CUS,/,4,/,(100),*

name=GSSALUBusyCycles
desc=#GeometryShader#Number of GPU cycles where scalar ALU instructions are being processed by the GS.
type=gpa_float64
usage=cycles
[GLGfx8]
SQ_GS_PERF_SEL_INST_CYCLES_SALU
eqn=0,NUM_CUS,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_GS*_PERF_SEL_INST_CYCLES_SALU[0..3]
eqn=0..3,sum4,NUM_CUS,/

name=PrimitiveAssemblyBusy
desc=#Timing#The percentage of GPUTime that primitive assembly (clipping and culling) is busy. High values may be caused by having many small primitives; mid to low values may indicate pixel shader or output buffer bottleneck.
type=gpa_float64
usage=percentage
[GLGfx8]
PA_SU_PERF_PAPC_CLIP_BUSY
PA_SU_PERF_PAPC_SU_STALLED_SC
PA_SU_PERF_PAPC_SU_OUTPUT_PRIM
PA_SU_PERF_PAPC_SU_OUTPUT_PRIM_DUAL
PA_SU_PERF_PAPC_SU_OUTPUT_CLIP_PRIM
PA_SU_PERF_PAPC_SU_OUTPUT_CLIP_PRIM_DUAL
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,1,-,2,3,+,4,+,5,(2),*,+,SU_CLOCKS_PRIM,*,-,NUM_PRIM_PIPES,/,(0),max,6,/,(100),*,(100),min
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
PA_SU*_PERF_PAPC_CLIP_BUSY[0..3]
PA_SU*_PERF_PAPC_SU_STALLED_SC[0..3]
PA_SU*_PERF_PAPC_SU_OUTPUT_PRIM[0..3]
PA_SU*_PERF_PAPC_SU_OUTPUT_PRIM_DUAL[0..3]
PA_SU*_PERF_PAPC_SU_OUTPUT_CLIP_PRIM[0..3]
PA_SU*_PERF_PAPC_SU_OUTPUT_CLIP_PRIM_DUAL[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,4,-,8,12,+,16,+,20,(2),*,+,SU_CLOCKS_PRIM,*,-,1,5,-,9,13,+,17,+,21,(2),*,+,SU_CLOCKS_PRIM,*,-,max,2,6,-,10,14,+,18,+,22,(2),*,+,SU_CLOCKS_PRIM,*,-,max,3,7,-,11,15,+,19,+,23,(2),*,+,SU_CLOCKS_PRIM,*,-,max,(0),max,24,/,(100),*,(100),min

name=PrimitiveAssemblyBusyCycles
desc=#Timing#Number of GPU cycles the primitive assembly (clipping and culling) is busy. High values may be caused by having many small primitives; mid to low values may indicate pixel shader or output buffer bottleneck.
type=gpa_float64
usage=cycles
[GLGfx8]
PA_SU_PERF_PAPC_CLIP_BUSY
PA_SU_PERF_PAPC_SU_STALLED_SC
PA_SU_PERF_PAPC_SU_OUTPUT_PRIM
PA_SU_PERF_PAPC_SU_OUTPUT_PRIM_DUAL
PA_SU_PERF_PAPC_SU_OUTPUT_CLIP_PRIM
PA_SU_PERF_PAPC_SU_OUTPUT_CLIP_PRIM_DUAL
eqn=0,1,-,2,3,+,4,+,5,(2),*,+,SU_CLOCKS_PRIM,*,-,NUM_PRIM_PIPES,/,(0),max
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
PA_SU*_PERF_PAPC_CLIP_BUSY[0..3]
PA_SU*_PERF_PAPC_SU_STALLED_SC[0..3]
PA_SU*_PERF_PAPC_SU_OUTPUT_PRIM[0..3]
PA_SU*_PERF_PAPC_SU_OUTPUT_PRIM_DUAL[0..3]
PA_SU*_PERF_PAPC_SU_OUTPUT_CLIP_PRIM[0..3]
PA_SU*_PERF_PAPC_SU_OUTPUT_CLIP_PRIM_DUAL[0..3]
eqn=0,4,-,8,12,+,16,+,20,(2),*,+,SU_CLOCKS_PRIM,*,-,1,5,-,9,13,+,17,+,21,(2),*,+,SU_CLOCKS_PRIM,*,-,max,2,6,-,10,14,+,18,+,22,(2),*,+,SU_CLOCKS_PRIM,*,-,max,3,7,-,11,15,+,19,+,23,(2),*,+,SU_CLOCKS_PRIM,*,-,max,(0),max

name=PrimitivesIn
desc=#PrimitiveAssembly#The number of primitives received by the hardware. This includes primitives generated by tessellation.
type=gpa_float64
usage=items
[GLGfx8]
PA_SU_PERF_PAPC_PA_INPUT_PRIM
eqn=0
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
PA_SU*_PERF_PAPC_PA_INPUT_PRIM[0..3]
eqn=0,1,2,3,sum4

name=CulledPrims
desc=#PrimitiveAssembly#The number of culled primitives. Typical reasons include scissor, the primitive having zero area, and back or front face culling.
type=gpa_float64
usage=items
[GLGfx8]
PA_SU_PERF_PAPC_CLPR_CULL_PRIM
PA_SU_PERF_PAPC_SU_ZERO_AREA_CULL_PRIM
PA_SU_PERF_PAPC_SU_BACK_FACE_CULL_PRIM
PA_SU_PERF_PAPC_SU_FRONT_FACE_CULL_PRIM
PA_SU_PERF_PAPC_SU_POLYMODE_FACE_CULL
eqn=0,1,+,2,+,3,+,4,+
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
PA_SU*_PERF_PAPC_CLPR_CULL_PRIM[0..3]
PA_SU*_PERF_PAPC_SU_ZERO_AREA_CULL_PRIM[0..3]
PA_SU*_PERF_PAPC_SU_BACK_FACE_CULL_PRIM[0..3]
PA_SU*_PERF_PAPC_SU_FRONT_FACE_CULL_PRIM[0..3]
PA_SU*_PERF_PAPC_SU_POLYMODE_FACE_CULL[0..3]
eqn=0,1,+,2,+,3,+,4,+,5,+,6,+,7,+,8,+,9,+,10,+,11,+,12,+,13,+,14,+,15,+,16,+,17,+,18,+,19,+

name=ClippedPrims
desc=#PrimitiveAssembly#The number of primitives that required one or more clipping operations due to intersecting the view volume or user clip planes.
type=gpa_float64
usage=items
[GLGfx8]
PA_SU_PERF_PAPC_CLPR_VVUCP_CLIP_PRIM
eqn=0
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
PA_SU*_PERF_PAPC_CLPR_VVUCP_CLIP_PRIM[0..3]
eqn=0,1,2,3,sum4

name=PAStalledOnRasterizer
desc=#PrimitiveAssembly#Percentage of GPUTime that primitive assembly waits for rasterization to be ready to accept data. This roughly indicates for what percentage of time the pipeline is bottlenecked by pixel operations.
type=gpa_float64
usage=percentage
[GLGfx8]
PA_SU_PERF_PAPC_SU_STALLED_SC
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,NUM_PRIM_PIPES,/,1,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
PA_SU*_PERF_PAPC_SU_STALLED_SC[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,1,max,2,max,3,max,4,/,(100),*

name=PAStalledOnRasterizerCycles
desc=#PrimitiveAssembly#Number of GPU cycles the primitive assembly waits for rasterization to be ready to accept data. Indicates the number of GPU cycles the pipeline is bottlenecked by pixel operations.
type=gpa_float64
usage=cycles
[GLGfx8]
PA_SU_PERF_PAPC_SU_STALLED_SC
eqn=0,NUM_PRIM_PIPES,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
PA_SU*_PERF_PAPC_SU_STALLED_SC[0..3]
eqn=0,1,max,2,max,3,max

name=PSPixelsOut
desc=#PixelShader#Pixels exported from shader to color buffers. Does not include killed or alpha tested pixels; if there are multiple render targets, each render target receives one export, so this will be 2 for 1 pixel written to two RTs.
type=gpa_float64
usage=items
[GLGfx8]
SX_PERF_SEL_DB0_PIXELS
SX_PERF_SEL_DB1_PIXELS
SX_PERF_SEL_DB2_PIXELS
SX_PERF_SEL_DB3_PIXELS
eqn=0,1,2,3,sum4
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SX*_PERF_SEL_DB0_PIXELS[0..3]
SX*_PERF_SEL_DB1_PIXELS[0..3]
SX*_PERF_SEL_DB2_PIXELS[0..3]
SX*_PERF_SEL_DB3_PIXELS[0..3]
eqn=0,1,2,3,sum4,4,5,6,7,sum4,8,9,10,11,sum4,12,13,14,15,sum4,sum4

name=PSExportStalls
desc=#PixelShader#Pixel shader output stalls. Percentage of GPUBusy. Should be zero for PS or further upstream limited cases; if not zero, indicates a bottleneck in late Z testing or in the color buffer.
type=gpa_float64
usage=percentage
[GLGfx8]
SX_PERF_SEL_DB0_PIXEL_STALL
SX_PERF_SEL_DB1_PIXEL_STALL
SX_PERF_SEL_DB2_PIXEL_STALL
SX_PERF_SEL_DB3_PIXEL_STALL
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,1,max,2,max,3,max,4,/,NUM_SHADER_ENGINES,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SX*_PERF_SEL_DB0_PIXEL_STALL[0..3]
SX*_PERF_SEL_DB1_PIXEL_STALL[0..3]
SX*_PERF_SEL_DB2_PIXEL_STALL[0..3]
SX*_PERF_SEL_DB3_PIXEL_STALL[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,1,max,2,max,3,max,4,max,5,max,6,max,7,max,8,max,9,max,10,max,11,max,12,max,13,max,14,max,15,max,16,/,(100),*

name=PSExportStallsCycles
desc=#PixelShader#Number of GPU cycles the pixel shader output stalls. Should be zero for PS or further upstream limited cases; if not zero, indicates a bottleneck in late Z testing or in the color buffer.
type=gpa_float64
usage=cycles
[GLGfx8]
SX_PERF_SEL_DB0_PIXEL_STALL
SX_PERF_SEL_DB1_PIXEL_STALL
SX_PERF_SEL_DB2_PIXEL_STALL
SX_PERF_SEL_DB3_PIXEL_STALL
eqn=0,1,max,2,max,3,max,NUM_SHADER_ENGINES,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SX*_PERF_SEL_DB0_PIXEL_STALL[0..3]
SX*_PERF_SEL_DB1_PIXEL_STALL[0..3]
SX*_PERF_SEL_DB2_PIXEL_STALL[0..3]
SX*_PERF_SEL_DB3_PIXEL_STALL[0..3]
eqn=0,1,max,2,max,3,max,4,max,5,max,6,max,7,max,8,max,9,max,10,max,11,max,12,max,13,max,14,max,15,max

name=PSVALUInstCount
desc=#PixelShader#Average number of vector ALU instructions executed in the PS. Affected by flow control.
type=gpa_float64
usage=items
[GLGfx8]
SQ_PS_PERF_SEL_INSTS_VALU
SQ_PS_PERF_SEL_WAVES
eqn=0,1,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_PS*_PERF_SEL_INSTS_VALU[0..3]
SQ_PS*_PERF_SEL_WAVES[0..3]
eqn=0..3,sum4,4..7,sum4,/

name=PSSALUInstCount
desc=#PixelShader#Average number of scalar ALU instructions executed in the PS. Affected by flow control.
type=gpa_float64
usage=items
[GLGfx8]
SQ_PS_PERF_SEL_INSTS_SALU
SQ_PS_PERF_SEL_WAVES
eqn=0,1,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_PS*_PERF_SEL_INSTS_SALU[0..3]
SQ_PS*_PERF_SEL_WAVES[0..3]
eqn=0..3,sum4,4..7,sum4,/

name=PSVALUBusy
desc=#PixelShader#The percentage of GPUTime vector ALU instructions are being processed by the PS.
type=gpa_float64
usage=percentage
[GLGfx8]
SQ_PS_PERF_SEL_INST_CYCLES_VALU
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,(4),*,NUM_SIMDS,/,1,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_PS*_PERF_SEL_INST_CYCLES_VALU[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0..3,sum4,(4),*,NUM_SIMDS,/,4,/,(100),*

name=PSVALUBusyCycles
desc=#PixelShader#Number of GPU cycles where vector ALU instructions are being processed by the PS.
type=gpa_float64
usage=cycles
[GLGfx8]
SQ_PS_PERF_SEL_INST_CYCLES_VALU
eqn=0,(4),*,NUM_SIMDS,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_PS*_PERF_SEL_INST_CYCLES_VALU[0..3]
eqn=0..3,sum4,(4),*,NUM_SIMDS,/

name=PSSALUBusy
desc=#PixelShader#The percentage of GPUTime scalar ALU instructions are being processed by the PS.
type=gpa_float64
usage=percentage
[GLGfx8]
SQ_PS_PERF_SEL_INST_CYCLES_SALU
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,NUM_CUS,/,1,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_PS*_PERF_SEL_INST_CYCLES_SALU[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0..3,sum4,NUM_CUS,/,4,/,(100),*

name=PSSALUBusyCycles
desc=#PixelShader#Number of GPU cycles where scalar ALU instructions are being processed by the PS.
type=gpa_float64
usage=cycles
[GLGfx8]
SQ_PS_PERF_SEL_INST_CYCLES_SALU
eqn=0,NUM_CUS,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_PS*_PERF_SEL_INST_CYCLES_SALU[0..3]
eqn=0..3,sum4,NUM_CUS,/

name=CSThreadGroups
desc=#ComputeShader#Total number of thread groups.
type=gpa_float64
usage=items
[GLGfx8]
SPI_PERF_CSG_NUM_THREADGROUPS
SPI_PERF_CSN_NUM_THREADGROUPS
eqn=0,1,+
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=0..7,sum8

name=CSWavefronts
desc=#ComputeShader#The total number of wavefronts used for the CS.
type=gpa_float64
usage=items
[GLGfx8]
SQ_CS_PERF_SEL_WAVES
eqn=0
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SPI*_PERF_CSG_WAVE[0..3]
SPI*_PERF_CSN_WAVE[0..3]
eqn=0..7,sum8

name=CSThreads
desc=#ComputeShader#The number of CS threads processed by the hardware.
type=gpa_float64
usage=items
[GLGfx8]
SQ_CS_PERF_SEL_ITEMS
eqn=0
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
SQ_CS*_PERF_SEL_ITEMS[0..3]
eqn=(0),SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,SQ_CS*_PERF_SEL_ITEMS,sum4,ifnotzero

name=CSVALUInsts
desc=#ComputeShader#The average number of vector ALU instructions executed per work-item (affected by flow control).
type=gpa_float64
usage=items
[GLGfx8]
SQ_CS_PERF_SEL_INSTS_VALU
SQ_CS_PERF_SEL_WAVES
eqn=(0),0,1,/,1,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_CS*_PERF_SEL_INSTS_VALU[0..3]
SQ_CS*_PERF_SEL_WAVES[0..3]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),SQ_CS*_PERF_SEL_INSTS_VALU,sum4,SQ_CS*_PERF_SEL_WAVES,sum4,/,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSVALUUtilization
desc=#ComputeShader#The percentage of active vector ALU threads in a wave. A lower number can mean either more thread divergence in a wave or that the work-group size is not a multiple of 64. Value range: 0% (bad), 100% (ideal - no thread divergence).
type=gpa_float64
usage=percentage
[GLGfx8]
SQ_CS_PERF_SEL_THREAD_CYCLES_VALU
SQ_CS_PERF_SEL_INST_CYCLES_VALU
eqn=(0),0,1,(64),*,/,(100),*,1,ifnotzero,(100),min
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_CS*_PERF_SEL_THREAD_CYCLES_VALU[0..3]
SQ_CS*_PERF_SEL_INST_CYCLES_VALU[0..3]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),SQ_CS*_PERF_SEL_THREAD_CYCLES_VALU,sum4,SQ_CS*_PERF_SEL_INST_CYCLES_VALU,sum4,(64),*,/,(100),*,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero,(100),min

name=CSSALUInsts
desc=#ComputeShader#The average number of scalar ALU instructions executed per work-item (affected by flow control).
type=gpa_float64
usage=items
[GLGfx8]
SQ_CS_PERF_SEL_INSTS_SALU
SQ_CS_PERF_SEL_WAVES
eqn=(0),0,1,/,1,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_CS*_PERF_SEL_INSTS_SALU[0..3]
SQ_CS*_PERF_SEL_WAVES[0..3]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),SQ_CS*_PERF_SEL_INSTS_SALU,sum4,SQ_CS*_PERF_SEL_WAVES,sum4,/,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSVFetchInsts
desc=#ComputeShader#The average number of vector fetch instructions from the video memory executed per work-item (affected by flow control).
type=gpa_float64
usage=items
[GLGfx8]
SQ_CS_PERF_SEL_INSTS_VMEM_RD
TA*_PERF_SEL_FLAT_READ_WAVEFRONTS[0..15]
SQ_CS_PERF_SEL_WAVES
eqn=(0),0,1..16,sum16,-,17,/,17,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_CS*_PERF_SEL_INSTS_VMEM_RD[0..3]
TA*_PERF_SEL_FLAT_READ_WAVEFRONTS[0..63]
SQ_CS*_PERF_SEL_WAVES[0..3]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),SQ_CS*_PERF_SEL_INSTS_VMEM_RD,sum4,TA*_PERF_SEL_FLAT_READ_WAVEFRONTS,sum64,-,SQ_CS*_PERF_SEL_WAVES,sum4,/,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSSFetchInsts
desc=#ComputeShader#The average number of scalar fetch instructions from the video memory executed per work-item (affected by flow control).
type=gpa_float64
usage=items
[GLGfx8]
SQ_CS_PERF_SEL_INSTS_SMEM
SQ_CS_PERF_SEL_WAVES
eqn=(0),0,1,/,1,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_CS*_PERF_SEL_INSTS_SMEM[0..3]
SQ_CS*_PERF_SEL_WAVES[0..3]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),SQ_CS*_PERF_SEL_INSTS_SMEM,sum4,SQ_CS*_PERF_SEL_WAVES,sum4,/,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSVWriteInsts
desc=#ComputeShader#The average number of vector write instructions to the video memory executed per work-item (affected by flow control).
type=gpa_float64
usage=items
[GLGfx8]
SQ_CS_PERF_SEL_INSTS_VMEM_WR
TA*_PERF_SEL_FLAT_WRITE_WAVEFRONTS[0..15]
SQ_CS_PERF_SEL_WAVES
eqn=(0),0,1..16,sum16,-,17,/,17,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_CS*_PERF_SEL_INSTS_VMEM_WR[0..3]
TA*_PERF_SEL_FLAT_WRITE_WAVEFRONTS[0..63]
SQ_CS*_PERF_SEL_WAVES[0..3]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),SQ_CS*_PERF_SEL_INSTS_VMEM_WR,sum4,TA*_PERF_SEL_FLAT_WRITE_WAVEFRONTS,sum64,-,SQ_CS*_PERF_SEL_WAVES,sum4,/,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSFlatVMemInsts
desc=#ComputeShader#The average number of FLAT instructions that read from or write to the video memory executed per work item (affected by flow control). Includes FLAT instructions that read from or write to scratch.
type=gpa_float64
usage=items
[GLGfx8]
SQ_CS_PERF_SEL_INSTS_FLAT
SQ_CS_PERF_SEL_INSTS_FLAT_LDS_ONLY
SQ_CS_PERF_SEL_WAVES
eqn=(0),0,1,-,2,/,2,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_CS*_PERF_SEL_INSTS_FLAT[0..3]
SQ_CS*_PERF_SEL_INSTS_FLAT_LDS_ONLY[0..3]
SQ_CS*_PERF_SEL_WAVES[0..3]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),SQ_CS*_PERF_SEL_INSTS_FLAT,sum4,SQ_CS*_PERF_SEL_INSTS_FLAT_LDS_ONLY,sum4,-,SQ_CS*_PERF_SEL_WAVES,sum4,/,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSVALUBusy
desc=#ComputeShader#The percentage of GPUTime vector ALU instructions are processed. Value range: 0% (bad) to 100% (optimal).
type=gpa_float64
usage=percentage
[GLGfx8]
SQ_CS_PERF_SEL_INST_CYCLES_VALU
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,(4),*,NUM_SIMDS,/,1,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_CS*_PERF_SEL_INST_CYCLES_VALU[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),SQ_CS*_PERF_SEL_INST_CYCLES_VALU,sum4,(4),*,NUM_SIMDS,/,GRBM_PERF_SEL_GUI_ACTIVE,/,(100),*,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSVALUBusyCycles
desc=#ComputeShader#Number of GPU cycles where vector ALU instructions are processed.
type=gpa_float64
usage=cycles
[GLGfx8]
SQ_CS_PERF_SEL_INST_CYCLES_VALU
eqn=0,(4),*,NUM_SIMDS,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_CS*_PERF_SEL_INST_CYCLES_VALU[0..3]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),0..3,sum4,(4),*,NUM_SIMDS,/,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSSALUBusy
desc=#ComputeShader#The percentage of GPUTime scalar ALU instructions are processed. Value range: 0% (bad) to 100% (optimal).
type=gpa_float64
usage=percentage
[GLGfx8]
SQ_CS_PERF_SEL_INST_CYCLES_SALU
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,NUM_CUS,/,1,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_CS*_PERF_SEL_INST_CYCLES_SALU[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),SQ_CS*_PERF_SEL_INST_CYCLES_SALU,sum4,NUM_CUS,/,GRBM_PERF_SEL_GUI_ACTIVE,/,(100),*,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSSALUBusyCycles
desc=#ComputeShader#Number of GPU cycles where scalar ALU instructions are processed.
type=gpa_float64
usage=cycles
[GLGfx8]
SQ_CS_PERF_SEL_INST_CYCLES_SALU
eqn=0,NUM_CUS,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_CS*_PERF_SEL_INST_CYCLES_SALU[0..3]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),0..3,sum4,NUM_CUS,/,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSMemUnitBusy
desc=#ComputeShader#The percentage of GPUTime the memory unit is active. The result includes the stall time (MemUnitStalled). This is measured with all extra fetches and writes and any cache or memory effects taken into account. Value range: 0% to 100% (fetch-bound).
type=gpa_float64
usage=percentage
[GLGfx8]
TA*_PERF_SEL_TA_BUSY[0..15]
GRBM_PERF_SEL_GUI_ACTIVE
SPI_PERF_CSG_NUM_THREADGROUPS
SPI_PERF_CSN_NUM_THREADGROUPS
eqn=(0),TA*_PERF_SEL_TA_BUSY,max16,GRBM_PERF_SEL_GUI_ACTIVE,/,NUM_SHADER_ENGINES,/,(100),*,SPI_PERF_CSG_NUM_THREADGROUPS,SPI_PERF_CSN_NUM_THREADGROUPS,+,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TA*_PERF_SEL_TA_BUSY[0..63]
GRBM_PERF_SEL_GUI_ACTIVE
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),TA*_PERF_SEL_TA_BUSY,max64,GRBM_PERF_SEL_GUI_ACTIVE,/,(100),*,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSMemUnitBusyCycles
desc=#ComputeShader#Number of GPU cycles the memory unit is active. The result includes the stall time (MemUnitStalled). This is measured with all extra fetches and writes and any cache or memory effects taken into account.
type=gpa_float64
usage=cycles
[GLGfx8]
TA*_PERF_SEL_TA_BUSY[0..15]
SPI_PERF_CSG_NUM_THREADGROUPS
SPI_PERF_CSN_NUM_THREADGROUPS
eqn=(0),0..15,max16,NUM_SHADER_ENGINES,/,SPI_PERF_CSG_NUM_THREADGROUPS,SPI_PERF_CSN_NUM_THREADGROUPS,+,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TA*_PERF_SEL_TA_BUSY[0..63]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),0..63,max64,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSMemUnitStalled
desc=#ComputeShader#The percentage of GPUTime the memory unit is stalled. Try reducing the number or size of fetches and writes if possible. Value range: 0% (optimal) to 100% (bad).
type=gpa_float64
usage=percentage
[GLGfx8]
TCP*_PERF_SEL_TCP_TA_DATA_STALL_CYCLES[0..15]
GRBM_PERF_SEL_GUI_ACTIVE
SPI_PERF_CSG_NUM_THREADGROUPS
SPI_PERF_CSN_NUM_THREADGROUPS
eqn=(0),TCP*_PERF_SEL_TCP_TA_DATA_STALL_CYCLES,max16,GRBM_PERF_SEL_GUI_ACTIVE,/,NUM_SHADER_ENGINES,/,(100),*,SPI_PERF_CSG_NUM_THREADGROUPS,SPI_PERF_CSN_NUM_THREADGROUPS,+,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TCP*_PERF_SEL_TCP_TA_DATA_STALL_CYCLES[0..63]
GRBM_PERF_SEL_GUI_ACTIVE
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),TCP*_PERF_SEL_TCP_TA_DATA_STALL_CYCLES,max64,GRBM_PERF_SEL_GUI_ACTIVE,/,(100),*,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSMemUnitStalledCycles
desc=#ComputeShader#Number of GPU cycles the memory unit is stalled. Try reducing the number or size of fetches and writes if possible.
type=gpa_float64
usage=cycles
[GLGfx8]
TCP*_PERF_SEL_TCP_TA_DATA_STALL_CYCLES[0..15]
SPI_PERF_CSG_NUM_THREADGROUPS
SPI_PERF_CSN_NUM_THREADGROUPS
eqn=(0),0..15,max16,NUM_SHADER_ENGINES,/,SPI_PERF_CSG_NUM_THREADGROUPS,SPI_PERF_CSN_NUM_THREADGROUPS,+,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TCP*_PERF_SEL_TCP_TA_DATA_STALL_CYCLES[0..63]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),0..63,max64,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSWriteUnitStalled
desc=#ComputeShader#The percentage of GPUTime the write unit is stalled.
type=gpa_float64
usage=percentage
[GLGfx8]
TCC*_PERF_SEL_MC_WRREQ_STALL[0..15]
GRBM_PERF_SEL_GUI_ACTIVE
SPI_PERF_CSG_NUM_THREADGROUPS
SPI_PERF_CSN_NUM_THREADGROUPS
eqn=(0),0..15,max16,GRBM_PERF_SEL_GUI_ACTIVE,/,(100),*,SPI_PERF_CSG_NUM_THREADGROUPS,SPI_PERF_CSN_NUM_THREADGROUPS,+,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TCC*_PERF_SEL_MC_WRREQ_STALL[0..15]
GRBM_PERF_SEL_GUI_ACTIVE
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),0..15,max16,GRBM_PERF_SEL_GUI_ACTIVE,/,(100),*,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSWriteUnitStalledCycles
desc=#ComputeShader#Number of GPU cycles the write unit is stalled.
type=gpa_float64
usage=cycles
[GLGfx8]
TCC*_PERF_SEL_MC_WRREQ_STALL[0..15]
SPI_PERF_CSG_NUM_THREADGROUPS
SPI_PERF_CSN_NUM_THREADGROUPS
eqn=(0),0..15,max16,SPI_PERF_CSG_NUM_THREADGROUPS,SPI_PERF_CSN_NUM_THREADGROUPS,+,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TCC*_PERF_SEL_MC_WRREQ_STALL[0..15]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),0..15,max16,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSGDSInsts
desc=#ComputeShader#The average number of GDS read or GDS write instructions executed per work item (affected by flow control).
type=gpa_float64
usage=items
[GLGfx8]
SQ_CS_PERF_SEL_INSTS_GDS
SQ_CS_PERF_SEL_WAVES
eqn=(0),0,1,/,1,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_CS*_PERF_SEL_INSTS_GDS[0..3]
SQ_CS*_PERF_SEL_WAVES[0..3]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),SQ_CS*_PERF_SEL_INSTS_GDS,sum4,SQ_CS*_PERF_SEL_WAVES,sum4,/,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSLDSInsts
desc=#ComputeShader#The average number of LDS read/write instructions executed per work-item (affected by flow control).
type=gpa_float64
usage=items
[GLGfx8]
SQ_CS_PERF_SEL_INSTS_LDS
SQ_CS_PERF_SEL_INSTS_FLAT
SQ_CS_PERF_SEL_WAVES
eqn=(0),0,1,-,2,/,2,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_CS*_PERF_SEL_INSTS_LDS[0..3]
SQ_CS*_PERF_SEL_INSTS_FLAT[0..3]
SQ_CS*_PERF_SEL_WAVES[0..3]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),SQ_CS*_PERF_SEL_INSTS_LDS,sum4,SQ_CS*_PERF_SEL_INSTS_FLAT,sum4,-,SQ_CS*_PERF_SEL_WAVES,sum4,/,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSFlatLDSInsts
desc=#ComputeShader#The average number of FLAT instructions that read from or write to LDS executed per work item (affected by flow control).
type=gpa_float64
usage=items
[GLGfx8]
SQ_CS_PERF_SEL_INSTS_FLAT_LDS_ONLY
SQ_CS_PERF_SEL_WAVES
eqn=(0),0,1,/,1,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_CS*_PERF_SEL_INSTS_FLAT_LDS_ONLY[0..3]
SQ_CS*_PERF_SEL_WAVES[0..3]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),SQ_CS*_PERF_SEL_INSTS_FLAT_LDS_ONLY,sum4,SQ_CS*_PERF_SEL_WAVES,sum4,/,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSALUStalledByLDS
desc=#ComputeShader#The percentage of GPUTime ALU units are stalled by the LDS input queue being full or the output queue being not ready. If there are LDS bank conflicts, reduce them. Otherwise, try reducing the number of LDS accesses if possible. Value range: 0% (optimal) to 100% (bad).
type=gpa_float64
usage=percentage
[GLGfx8]
SQ_PERF_SEL_WAIT_INST_LDS
SQ_PERF_SEL_WAVES
GRBM_PERF_SEL_GUI_ACTIVE
eqn=(0),0,1,/,2,/,NUM_SHADER_ENGINES,/,(100),*,1,ifnotzero
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_CS*_PERF_SEL_WAIT_INST_LDS[0..3]
SQ_CS*_PERF_SEL_WAVES[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),SQ_CS*_PERF_SEL_WAIT_INST_LDS,sum4,SQ_CS*_PERF_SEL_WAVES,sum4,/,GRBM_PERF_SEL_GUI_ACTIVE,/,NUM_SHADER_ENGINES,/,(100),*,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSALUStalledByLDSCycles
desc=#ComputeShader#Number of GPU cycles the ALU units are stalled by the LDS input queue being full or the output queue being not ready. If there are LDS bank conflicts, reduce them. Otherwise, try reducing the number of LDS accesses if possible.
type=gpa_float64
usage=cycles
[GLGfx8]
SQ_PERF_SEL_WAIT_INST_LDS
eqn=0,NUM_SHADER_ENGINES,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_CS*_PERF_SEL_WAIT_INST_LDS[0..3]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),0..3,sum4,NUM_SHADER_ENGINES,/,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSLDSBankConflict
desc=#ComputeShader#The percentage of GPUTime LDS is stalled by bank conflicts. Value range: 0% (optimal) to 100% (bad).
type=gpa_float64
usage=percentage
[GLGfx8]
SQ_CS_PERF_SEL_LDS_BANK_CONFLICT
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,1,/,NUM_SIMDS,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_CS*_PERF_SEL_LDS_BANK_CONFLICT[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),SQ_CS*_PERF_SEL_LDS_BANK_CONFLICT,sum4,GRBM_PERF_SEL_GUI_ACTIVE,/,NUM_SIMDS,/,(100),*,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=CSLDSBankConflictCycles
desc=#ComputeShader#Number of GPU cycles the LDS is stalled by bank conflicts. Value range: 0 (optimal) to GPUBusyCycles (bad).
type=gpa_float64
usage=cycles
[GLGfx8]
SQ_CS_PERF_SEL_LDS_BANK_CONFLICT
eqn=0,NUM_SIMDS,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
SQ_CS*_PERF_SEL_LDS_BANK_CONFLICT[0..3]
SPI*_PERF_CSG_NUM_THREADGROUPS[0..3]
SPI*_PERF_CSN_NUM_THREADGROUPS[0..3]
eqn=(0),0..3,sum4,NUM_SIMDS,/,SPI*_PERF_CSG_NUM_THREADGROUPS,SPI*_PERF_CSN_NUM_THREADGROUPS,sum8,ifnotzero

name=TexUnitBusy
desc=#Timing#The percentage of GPUTime the texture unit is active. This is measured with all extra fetches and any cache or memory effects taken into account.
type=gpa_float64
usage=percentage
[GLGfx8]
TA*_PERF_SEL_TA_BUSY[0..15]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0..15,max16,16,/,NUM_SHADER_ENGINES,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TA*_PERF_SEL_TA_BUSY[0..63]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0..63,max64,64,/,(100),*

name=TexUnitBusyCycles
desc=#Timing#Number of GPU cycles the texture unit is active. This is measured with all extra fetches and any cache or memory effects taken into account.
type=gpa_float64
usage=cycles
[GLGfx8]
TA*_PERF_SEL_TA_BUSY[0..15]
eqn=0..15,max16,NUM_SHADER_ENGINES,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TA*_PERF_SEL_TA_BUSY[0..63]
eqn=0..63,max64

name=TexTriFilteringPct
desc=#TextureUnit#Percentage of pixels that received trilinear filtering. Note that not all pixels for which trilinear filtering is enabled will receive it (e.g. if the texture is magnified).
type=gpa_float64
usage=percentage
[GLGfx8]
TA*_PERF_SEL_MIP_2_CYCLE_PIXELS[0..15]
TA*_PERF_SEL_MIP_1_CYCLE_PIXELS[0..15]
eqn=0..15,sum16,16..31,sum16,0..15,sum16,+,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TA*_PERF_SEL_MIP_2_CYCLE_PIXELS[0..63]
TA*_PERF_SEL_MIP_1_CYCLE_PIXELS[0..63]
eqn=0..63,sum64,64..127,sum64,0..63,sum64,+,/,(100),*

name=TexTriFilteringCount
desc=#TextureUnit#Count of pixels that received trilinear filtering. Note that not all pixels for which trilinear filtering is enabled will receive it (e.g. if the texture is magnified).
type=gpa_float64
usage=items
[GLGfx8]
TA*_PERF_SEL_MIP_2_CYCLE_PIXELS[0..15]
eqn=0..15,sum16
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TA*_PERF_SEL_MIP_2_CYCLE_PIXELS[0..63]
eqn=0..63,sum64

name=NoTexTriFilteringCount
desc=#TextureUnit#Count of pixels that did not receive trilinear filtering.
type=gpa_float64
usage=items
[GLGfx8]
TA*_PERF_SEL_MIP_1_CYCLE_PIXELS[0..15]
eqn=0..15,sum16
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TA*_PERF_SEL_MIP_1_CYCLE_PIXELS[0..63]
eqn=0..63,sum64

name=TexVolFilteringPct
desc=#TextureUnit#Percentage of pixels that received volume filtering.
type=gpa_float64
usage=percentage
[GLGfx8]
TA*_PERF_SEL_VOL_2_CYCLE_PIXELS[0..15]
TA*_PERF_SEL_VOL_1_CYCLE_PIXELS[0..15]
eqn=0..15,sum16,16..31,sum16,0..15,sum16,+,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TA*_PERF_SEL_VOL_2_CYCLE_PIXELS[0..63]
TA*_PERF_SEL_VOL_1_CYCLE_PIXELS[0..63]
eqn=0..63,sum64,64..127,sum64,0..63,sum64,+,/,(100),*

name=TexVolFilteringCount
desc=#TextureUnit#Count of pixels that received volume filtering.
type=gpa_float64
usage=items
[GLGfx8]
TA*_PERF_SEL_VOL_2_CYCLE_PIXELS[0..15]
eqn=0..15,sum16
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TA*_PERF_SEL_VOL_2_CYCLE_PIXELS[0..63]
eqn=0..63,sum64

name=NoTexVolFilteringCount
desc=#TextureUnit#Count of pixels that did not receive volume filtering.
type=gpa_float64
usage=items
[GLGfx8]
TA*_PERF_SEL_VOL_1_CYCLE_PIXELS[0..15]
eqn=0..15,sum16
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TA*_PERF_SEL_VOL_1_CYCLE_PIXELS[0..63]
eqn=0..63,sum64

name=TexAveAnisotropy
desc=#TextureUnit#The average degree of anisotropy applied. A number between 1 and 16. The anisotropic filtering algorithm only applies samples where they are required (e.g. there will be no extra anisotropic samples if the view vector is perpendicular to the surface) so this can be much lower than the requested anisotropy.
type=gpa_float64
usage=Items
[GLGfx8]
TA*_PERF_SEL_ANISO_1_CYCLE_QUADS[0..15]
TA*_PERF_SEL_ANISO_2_CYCLE_QUADS[0..15]
TA*_PERF_SEL_ANISO_4_CYCLE_QUADS[0..15]
TA*_PERF_SEL_ANISO_6_CYCLE_QUADS[0..15]
TA*_PERF_SEL_ANISO_8_CYCLE_QUADS[0..15]
TA*_PERF_SEL_ANISO_10_CYCLE_QUADS[0..15]
TA*_PERF_SEL_ANISO_12_CYCLE_QUADS[0..15]
TA*_PERF_SEL_ANISO_14_CYCLE_QUADS[0..15]
TA*_PERF_SEL_ANISO_16_CYCLE_QUADS[0..15]
eqn=0..15,sum16,(2),16..31,sum16,*,+,(4),32..47,sum16,*,+,(6),48..63,sum16,*,+,(8),64..79,sum16,*,+,(10),80..95,sum16,*,+,(12),96..111,sum16,*,+,(14),112..127,sum16,*,+,(16),128..143,sum16,*,+,0..15,sum16,16..31,sum16,+,32..47,sum16,+,48..63,sum16,+,64..79,sum16,+,80..95,sum16,+,96..111,sum16,+,112..127,sum16,+,128..143,sum16,+,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TA*_PERF_SEL_ANISO_1_CYCLE_QUADS[0..63]
TA*_PERF_SEL_ANISO_2_CYCLE_QUADS[0..63]
TA*_PERF_SEL_ANISO_4_CYCLE_QUADS[0..63]
TA*_PERF_SEL_ANISO_6_CYCLE_QUADS[0..63]
TA*_PERF_SEL_ANISO_8_CYCLE_QUADS[0..63]
TA*_PERF_SEL_ANISO_10_CYCLE_QUADS[0..63]
TA*_PERF_SEL_ANISO_12_CYCLE_QUADS[0..63]
TA*_PERF_SEL_ANISO_14_CYCLE_QUADS[0..63]
TA*_PERF_SEL_ANISO_16_CYCLE_QUADS[0..63]
eqn=0..63,sum64,(2),64..127,sum64,*,+,(4),128..191,sum64,*,+,(6),192..255,sum64,*,+,(8),256..319,sum64,*,+,(10),320..383,sum64,*,+,(12),384..447,sum64,*,+,(14),448..511,sum64,*,+,(16),512..575,sum64,*,+,0..63,sum64,64..127,sum64,+,128..191,sum64,+,192..255,sum64,+,256..319,sum64,+,320..383,sum64,+,384..447,sum64,+,448..511,sum64,+,512..575,sum64,+,/

name=DepthStencilTestBusy
desc=#Timing#Percentage of time GPU spent performing depth and stencil tests relative to GPUBusy.
type=gpa_float64
usage=percentage
[GLGfx8]
DB*_PERF_SEL_OP_PIPE_BUSY[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,1,max,2,max,3,max,4,/,NUM_SHADER_ENGINES,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
DB*_PERF_SEL_OP_PIPE_BUSY[0..15]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0..15,max16,16,/,(100),*

name=DepthStencilTestBusyCount
desc=#Timing#Number of GPU cycles spent performing depth and stencil tests.
type=gpa_float64
usage=cycles
[GLGfx8]
DB*_PERF_SEL_OP_PIPE_BUSY[0..3]
eqn=0,1,max,2,max,3,max,NUM_SHADER_ENGINES,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
DB*_PERF_SEL_OP_PIPE_BUSY[0..15]
eqn=0..15,max16

name=HiZTilesAccepted
desc=#DepthAndStencil#Percentage of tiles accepted by HiZ and will be rendered to the depth or color buffers.
type=gpa_float64
usage=percentage
[GLGfx8]
DB*_PERF_SEL_DB_SC_TILE_CULLED[0..3]
DB*_PERF_SEL_SC_DB_TILE_TILES[0..3]
eqn=0..3,sum4,4..7,sum4,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
DB*_PERF_SEL_DB_SC_TILE_CULLED[0..15]
DB*_PERF_SEL_SC_DB_TILE_TILES[0..15]
eqn=0..15,sum16,16..31,sum16,/,(100),*

name=HiZTilesAcceptedCount
desc=#DepthAndStencil#Count of tiles accepted by HiZ and will be rendered to the depth or color buffers.
type=gpa_float64
usage=items
[GLGfx8]
DB*_PERF_SEL_SC_DB_TILE_TILES[0..3]
eqn=0..3,sum4
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
DB*_PERF_SEL_SC_DB_TILE_TILES[0..15]
eqn=0..15,sum16

name=HiZTilesRejectedCount
desc=#DepthAndStencil#Count of tiles not accepted by HiZ.
type=gpa_float64
usage=items
[GLGfx8]
DB*_PERF_SEL_DB_SC_TILE_CULLED[0..3]
eqn=0..3,sum4
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
DB*_PERF_SEL_DB_SC_TILE_CULLED[0..15]
eqn=0..15,sum16

name=PreZTilesDetailCulled
desc=#DepthAndStencil#Percentage of tiles rejected because the associated prim had no contributing area.
type=gpa_float64
usage=percentage
[GLGfx8]
DB*_PERF_SEL_SC_DB_TILE_TILES[0..3]
DB*_PERF_SEL_SC_DB_QUAD_KILLED_TILES[0..3]
eqn=4..7,sum4,0..3,sum4,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
DB*_PERF_SEL_SC_DB_TILE_TILES[0..15]
DB*_PERF_SEL_SC_DB_QUAD_KILLED_TILES[0..15]
eqn=16..31,sum16,0..15,sum16,/,(100),*

name=PreZTilesDetailCulledCount
desc=#DepthAndStencil#Count of tiles rejected because the associated primitive had no contributing area.
type=gpa_float64
usage=items
[GLGfx8]
DB*_PERF_SEL_SC_DB_QUAD_KILLED_TILES[0..3]
eqn=0..3,sum4
[DX12Gfx8]
[VKGfx8]
[DX11Gfx8]
DB*_PERF_SEL_SC_DB_QUAD_KILLED_TILES[0..15]
eqn=0..15,sum16

name=PreZTilesDetailSurvivingCount
desc=#DepthAndStencil#Count of tiles surviving because the associated primitive had contributing area.
type=gpa_float64
usage=items
[GLGfx8]
DB*_PERF_SEL_SC_DB_TILE_TILES[0..3]
eqn=0..3,sum4
[DX12Gfx8]
[VKGfx8]
[DX11Gfx8]
DB*_PERF_SEL_SC_DB_TILE_TILES[0..15]
eqn=0..15,sum16

name=HiZQuadsCulled
desc=#DepthAndStencil#Percentage of quads that did not have to continue on in the pipeline after HiZ. They may be written directly to the depth buffer, or culled completely. Consistently low values here may suggest that the Z-range is not being fully utilized.
type=gpa_float64
usage=percentage
[GLGfx8]
PA_SC_QZ0_QUAD_COUNT
PA_SC_QZ1_QUAD_COUNT
PA_SC_QZ2_QUAD_COUNT
PA_SC_QZ3_QUAD_COUNT
PA_SC_P0_HIZ_QUAD_COUNT
PA_SC_P1_HIZ_QUAD_COUNT
PA_SC_P2_HIZ_QUAD_COUNT
PA_SC_P3_HIZ_QUAD_COUNT
eqn=0,1,+,2,+,3,+,4,5,+,6,+,7,+,-,(0),max,0,1,+,2,+,3,+,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
PA_SC*_QZ0_QUAD_COUNT[0..3]
PA_SC*_QZ1_QUAD_COUNT[0..3]
PA_SC*_QZ2_QUAD_COUNT[0..3]
PA_SC*_QZ3_QUAD_COUNT[0..3]
PA_SC*_P0_HIZ_QUAD_COUNT[0..3]
PA_SC*_P1_HIZ_QUAD_COUNT[0..3]
PA_SC*_P2_HIZ_QUAD_COUNT[0..3]
PA_SC*_P3_HIZ_QUAD_COUNT[0..3]
eqn=0..15,sum16,16..31,sum16,-,(0),max,0..15,sum16,/,(100),*

name=HiZQuadsCulledCount
desc=#DepthAndStencil#Count of quads that did not have to continue on in the pipeline after HiZ. They may be written directly to the depth buffer, or culled completely. Consistently low values here may suggest that the Z-range is not being fully utilized.
type=gpa_float64
usage=items
[GLGfx8]
PA_SC_QZ0_QUAD_COUNT
PA_SC_QZ1_QUAD_COUNT
PA_SC_QZ2_QUAD_COUNT
PA_SC_QZ3_QUAD_COUNT
PA_SC_P0_HIZ_QUAD_COUNT
PA_SC_P1_HIZ_QUAD_COUNT
PA_SC_P2_HIZ_QUAD_COUNT
PA_SC_P3_HIZ_QUAD_COUNT
eqn=0,1,+,2,+,3,+,4,-,5,-,6,-,7,-,(0),max
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
PA_SC*_QZ0_QUAD_COUNT[0..3]
PA_SC*_QZ1_QUAD_COUNT[0..3]
PA_SC*_QZ2_QUAD_COUNT[0..3]
PA_SC*_QZ3_QUAD_COUNT[0..3]
PA_SC*_P0_HIZ_QUAD_COUNT[0..3]
PA_SC*_P1_HIZ_QUAD_COUNT[0..3]
PA_SC*_P2_HIZ_QUAD_COUNT[0..3]
PA_SC*_P3_HIZ_QUAD_COUNT[0..3]
eqn=0..15,sum16,16..31,sum16,-,(0),max

name=HiZQuadsAcceptedCount
desc=#DepthAndStencil#Count of quads that did continue on in the pipeline after HiZ.
type=gpa_float64
usage=items
[GLGfx8]
PA_SC_P0_HIZ_QUAD_COUNT
PA_SC_P1_HIZ_QUAD_COUNT
PA_SC_P2_HIZ_QUAD_COUNT
PA_SC_P3_HIZ_QUAD_COUNT
eqn=0,1,+,2,+,3,+
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
PA_SC*_P0_HIZ_QUAD_COUNT[0..3]
PA_SC*_P1_HIZ_QUAD_COUNT[0..3]
PA_SC*_P2_HIZ_QUAD_COUNT[0..3]
PA_SC*_P3_HIZ_QUAD_COUNT[0..3]
eqn=0..15,sum16


name=PreZQuadsCulled
desc=#DepthAndStencil#Percentage of quads rejected based on the detailZ and earlyZ tests.
type=gpa_float64
usage=percentage
[GLGfx8]
PA_SC_QZ0_QUAD_COUNT
PA_SC_QZ1_QUAD_COUNT
PA_SC_QZ2_QUAD_COUNT
PA_SC_QZ3_QUAD_COUNT
PA_SC_EARLYZ_QUAD_COUNT
PA_SC_P0_HIZ_QUAD_COUNT
PA_SC_P1_HIZ_QUAD_COUNT
PA_SC_P2_HIZ_QUAD_COUNT
PA_SC_P3_HIZ_QUAD_COUNT
eqn=5,6,+,7,+,8,+,4,-,(0),max,0,1,+,2,+,3,+,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
PA_SC*_QZ0_QUAD_COUNT[0..3]
PA_SC*_QZ1_QUAD_COUNT[0..3]
PA_SC*_QZ2_QUAD_COUNT[0..3]
PA_SC*_QZ3_QUAD_COUNT[0..3]
PA_SC*_EARLYZ_QUAD_COUNT[0..3]
PA_SC*_P0_HIZ_QUAD_COUNT[0..3]
PA_SC*_P1_HIZ_QUAD_COUNT[0..3]
PA_SC*_P2_HIZ_QUAD_COUNT[0..3]
PA_SC*_P3_HIZ_QUAD_COUNT[0..3]
eqn=20..35,sum16,16..19,sum4,-,(0),max,0..15,sum16,/,(100),*

name=PreZQuadsCulledCount
desc=#DepthAndStencil#Count of quads rejected based on the detailZ and earlyZ tests.
type=gpa_float64
usage=items
[GLGfx8]
PA_SC_EARLYZ_QUAD_COUNT
PA_SC_P0_HIZ_QUAD_COUNT
PA_SC_P1_HIZ_QUAD_COUNT
PA_SC_P2_HIZ_QUAD_COUNT
PA_SC_P3_HIZ_QUAD_COUNT
eqn=0,1,+,2,+,3,+,4,+
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
PA_SC*_EARLYZ_QUAD_COUNT[0..3]
PA_SC*_P0_HIZ_QUAD_COUNT[0..3]
PA_SC*_P1_HIZ_QUAD_COUNT[0..3]
PA_SC*_P2_HIZ_QUAD_COUNT[0..3]
PA_SC*_P3_HIZ_QUAD_COUNT[0..3]
eqn=0..15,sum16,16..19,sum4,+

name=PreZQuadsSurvivingCount
desc=#DepthAndStencil#Count of quads surviving detailZ and earlyZ tests.
type=gpa_float64
usage=items
[GLGfx8]
PA_SC_QZ0_QUAD_COUNT
PA_SC_QZ1_QUAD_COUNT
PA_SC_QZ2_QUAD_COUNT
PA_SC_QZ3_QUAD_COUNT
PA_SC_EARLYZ_QUAD_COUNT
PA_SC_P0_HIZ_QUAD_COUNT
PA_SC_P1_HIZ_QUAD_COUNT
PA_SC_P2_HIZ_QUAD_COUNT
PA_SC_P3_HIZ_QUAD_COUNT
eqn=0,1,+,2,+,3,+,4,-,5,-,6,-,7,-,8,-,(0),max
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
PA_SC*_QZ0_QUAD_COUNT[0..3]
PA_SC*_QZ1_QUAD_COUNT[0..3]
PA_SC*_QZ2_QUAD_COUNT[0..3]
PA_SC*_QZ3_QUAD_COUNT[0..3]
PA_SC*_P0_HIZ_QUAD_COUNT[0..3]
PA_SC*_P1_HIZ_QUAD_COUNT[0..3]
PA_SC*_P2_HIZ_QUAD_COUNT[0..3]
PA_SC*_P3_HIZ_QUAD_COUNT[0..3]
eqn=0..15,sum16,16..31,sum16,-,(0),max

name=PostZQuads
desc=#DepthAndStencil#Percentage of quads for which the pixel shader will run and may be postZ tested.
type=gpa_float64
usage=percentage
[GLGfx8]
PA_SC_EARLYZ_QUAD_COUNT
PA_SC_QZ0_QUAD_COUNT
PA_SC_QZ1_QUAD_COUNT
PA_SC_QZ2_QUAD_COUNT
PA_SC_QZ3_QUAD_COUNT
eqn=0,1,2,+,3,+,4,+,/,(100),*,(100),min
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
PA_SC*_EARLYZ_QUAD_COUNT[0..3]
PA_SC*_QZ0_QUAD_COUNT[0..3]
PA_SC*_QZ1_QUAD_COUNT[0..3]
PA_SC*_QZ2_QUAD_COUNT[0..3]
PA_SC*_QZ3_QUAD_COUNT[0..3]
eqn=0..3,sum4,4..19,sum16,/,(100),*

name=PostZQuadCount
desc=#DepthAndStencil#Count of quads for which the pixel shader will run and may be postZ tested.
type=gpa_float64
usage=items
[GLGfx8]
PA_SC_EARLYZ_QUAD_COUNT
eqn=0
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
PA_SC*_EARLYZ_QUAD_COUNT[0..3]
eqn=0..3,sum4

name=PreZSamplesPassing
desc=#DepthAndStencil#Number of samples tested for Z before shading and passed.
type=gpa_float64
usage=items
[GLGfx8]
DB*_PERF_SEL_PREZ_SAMPLES_PASSING_Z[0..3]
eqn=0..3,sum4
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
DB*_PERF_SEL_PREZ_SAMPLES_PASSING_Z[0..15]
eqn=0..15,sum16

name=PreZSamplesFailingS
desc=#DepthAndStencil#Number of samples tested for Z before shading and failed stencil test.
type=gpa_float64
usage=items
[GLGfx8]
DB*_PERF_SEL_PREZ_SAMPLES_FAILING_S[0..3]
eqn=0..3,sum4
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
DB*_PERF_SEL_PREZ_SAMPLES_FAILING_S[0..15]
eqn=0..15,sum16

name=PreZSamplesFailingZ
desc=#DepthAndStencil#Number of samples tested for Z before shading and failed Z test.
type=gpa_float64
usage=items
[GLGfx8]
DB*_PERF_SEL_PREZ_SAMPLES_FAILING_Z[0..3]
eqn=0..3,sum4
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
DB*_PERF_SEL_PREZ_SAMPLES_FAILING_Z[0..15]
eqn=0..15,sum16

name=PostZSamplesPassing
desc=#DepthAndStencil#Number of samples tested for Z after shading and passed.
type=gpa_float64
usage=items
[GLGfx8]
DB*_PERF_SEL_POSTZ_SAMPLES_PASSING_Z[0..3]
eqn=0..3,sum4
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
DB*_PERF_SEL_POSTZ_SAMPLES_PASSING_Z[0..15]
eqn=0..15,sum16

name=PostZSamplesFailingS
desc=#DepthAndStencil#Number of samples tested for Z after shading and failed stencil test.
type=gpa_float64
usage=items
[GLGfx8]
DB*_PERF_SEL_POSTZ_SAMPLES_FAILING_S[0..3]
eqn=0..3,sum4
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
DB*_PERF_SEL_POSTZ_SAMPLES_FAILING_S[0..15]
eqn=0..15,sum16

name=PostZSamplesFailingZ
desc=#DepthAndStencil#Number of samples tested for Z after shading and failed Z test.
type=gpa_float64
usage=items
[GLGfx8]
DB*_PERF_SEL_POSTZ_SAMPLES_FAILING_Z[0..3]
eqn=0..3,sum4
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
DB*_PERF_SEL_POSTZ_SAMPLES_FAILING_Z[0..15]
eqn=0..15,sum16

name=ZUnitStalled
desc=#DepthAndStencil#The percentage of GPUTime the depth buffer spends waiting for the color buffer to be ready to accept data. High figures here indicate a bottleneck in color buffer operations.
type=gpa_float64
usage=percentage
[GLGfx8]
DB*_PERF_SEL_DB_CB_LQUAD_STALLS[0..3]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0,1,max,2,max,3,max,4,/,NUM_SHADER_ENGINES,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
DB*_PERF_SEL_DB_CB_LQUAD_STALLS[0..15]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0..15,max16,16,/,(100),*

name=ZUnitStalledCycles
desc=#DepthAndStencil#Number of GPU cycles the depth buffer spends waiting for the color buffer to be ready to accept data. Larger numbers indicate a bottleneck in color buffer operations.
type=gpa_float64
usage=cycles
[GLGfx8]
DB*_PERF_SEL_DB_CB_LQUAD_STALLS[0..3]
eqn=0,1,max,2,max,3,max,NUM_SHADER_ENGINES,/
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
DB*_PERF_SEL_DB_CB_LQUAD_STALLS[0..15]
eqn=0..15,max16

name=DBMemRead
desc=#DepthAndStencil#Number of bytes read from the depth buffer.
type=gpa_float64
usage=bytes
[GLGfx8]
DB*_PERF_SEL_TILE_RD_SENDS[0..3]
DB*_PERF_SEL_QUAD_RD_32BYTE_REQS[0..3]
eqn=0..3,sum4,(256),*,4..7,sum4,(32),*,+
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
DB*_PERF_SEL_TILE_RD_SENDS[0..15]
DB*_PERF_SEL_QUAD_RD_32BYTE_REQS[0..15]
eqn=0..15,sum16,(256),*,16..31,sum16,(32),*,+

name=DBMemWritten
desc=#DepthAndStencil#Number of bytes written to the depth buffer.
type=gpa_float64
usage=bytes
[GLGfx8]
DB*_PERF_SEL_TILE_WR_SENDS[0..3]
DB*_PERF_SEL_QUAD_WR_SENDS[0..3]
eqn=0..3,sum4,(32),*,4..7,sum4,(32),*,+
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
DB*_PERF_SEL_TILE_WR_SENDS[0..15]
DB*_PERF_SEL_QUAD_WR_SENDS[0..15]
eqn=0..15,sum16,(32),*,16..31,sum16,(32),*,+

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; The following are new on R8xx
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;Remove this since mostly it is duplicate of the psPixelsOut and the value is not correct when profiling alone.
;name=PixelsAtCB
;desc=#ColorBuffer#Number of pixels drawn into the the color buffer.
;type=gpa_float64
;usage=items
;[GLGfx8]
;CB0_PERF_SEL_DRAWN_PIXEL
;CB1_PERF_SEL_DRAWN_PIXEL
;[DX11Gfx8]
;[DX12Gfx8]
;[VKGfx8]
;CB0_PERF_SEL_DRAWN_PIXEL
;CB1_PERF_SEL_DRAWN_PIXEL
;eqn=0,1,+

name=CBMemRead
desc=#ColorBuffer#Number of bytes read from the color buffer.
type=gpa_float64
usage=bytes
[GLGfx8]
CB*_PERF_SEL_CC_MC_READ_REQUEST[0..3]
eqn=0..3,sum4,(32),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
CB*_PERF_SEL_CC_MC_READ_REQUEST[0..15]
eqn=0..15,sum16,(32),*

name=CBColorAndMaskRead
desc=#ColorBuffer#Total number of bytes read from the color and mask buffers.
type=gpa_float64
usage=bytes
[GLGfx8]
CB*_PERF_SEL_FC_MC_DCC_READ_REQUEST[0..3]
CB*_PERF_SEL_CM_MC_READ_REQUEST[0..3]
CB*_PERF_SEL_FC_MC_READ_REQUEST[0..3]
CB*_PERF_SEL_CC_MC_READ_REQUEST[0..3]
eqn=0..15,sum16,(32),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
CB*_PERF_SEL_FC_MC_DCC_READ_REQUEST[0..15]
CB*_PERF_SEL_CM_MC_READ_REQUEST[0..15]
CB*_PERF_SEL_FC_MC_READ_REQUEST[0..15]
CB*_PERF_SEL_CC_MC_READ_REQUEST[0..15]
eqn=0..63,sum64,(32),*

name=CBMemWritten
desc=#ColorBuffer#Number of bytes written to the color buffer.
type=gpa_float64
usage=bytes
[GLGfx8]
CB*_PERF_SEL_CC_MC_WRITE_REQUEST[0..3]
eqn=0..3,sum4,(32),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
CB*_PERF_SEL_CC_MC_WRITE_REQUEST[0..15]
eqn=0..15,sum16,(32),*

name=CBColorAndMaskWritten
desc=#ColorBuffer#Total number of bytes written to the color and mask buffers.
type=gpa_float64
usage=bytes
[GLGfx8]
CB*_PERF_SEL_FC_MC_DCC_WRITE_REQUEST[0..3]
CB*_PERF_SEL_CM_MC_WRITE_REQUEST[0..3]
CB*_PERF_SEL_FC_MC_WRITE_REQUEST[0..3]
CB*_PERF_SEL_CC_MC_WRITE_REQUEST[0..3]
eqn=0..15,sum16,(32),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
CB*_PERF_SEL_FC_MC_DCC_WRITE_REQUEST[0..15]
CB*_PERF_SEL_CM_MC_WRITE_REQUEST[0..15]
CB*_PERF_SEL_FC_MC_WRITE_REQUEST[0..15]
CB*_PERF_SEL_CC_MC_WRITE_REQUEST[0..15]
eqn=0..63,sum64,(32),*

name=CBSlowPixelPct
desc=#ColorBuffer#Percentage of pixels written to the color buffer using a half-rate or quarter-rate format.
type=gpa_float64
usage=percentage
[GLGfx8]
CB*_PERF_SEL_EXPORT_32_ABGR_QUAD_FRAGMENT[0..3]
CB*_PERF_SEL_DRAWN_QUAD_FRAGMENT[0..3]
eqn=0..3,sum4,4..7,sum4,/,(100),*,(100),min
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
CB*_PERF_SEL_EXPORT_32_ABGR_QUAD_FRAGMENT[0..15]
CB*_PERF_SEL_DRAWN_QUAD_FRAGMENT[0..15]
eqn=0..15,sum16,16..31,sum16,/,(100),*,(100),min

name=CBSlowPixelCount
desc=#ColorBuffer#Number of pixels written to the color buffer using a half-rate or quarter-rate format.
type=gpa_float64
usage=items
[GLGfx8]
CB*_PERF_SEL_EXPORT_32_ABGR_QUAD_FRAGMENT[0..3]
eqn=0..3,sum4
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
CB*_PERF_SEL_EXPORT_32_ABGR_QUAD_FRAGMENT[0..15]
eqn=0..15,sum16

name=FetchSize
desc=#GlobalMemory#The total bytes fetched from the video memory. This is measured with all extra fetches and any cache or memory effects taken into account.
type=gpa_float64
usage=bytes
[GLGfx8]
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TCC*_PERF_SEL_MC_RDREQ[0..15]
eqn=0..15,sum16,(32),*

name=WriteSize
desc=#GlobalMemory#The total bytes written to the video memory. This is measured with all extra fetches and any cache or memory effects taken into account.
type=gpa_float64
usage=bytes
[GLGfx8]
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TCC*_PERF_SEL_MC_WRREQ[0..15]
eqn=0..15,sum16,(32),*

name=CacheHit
desc=#GlobalMemory#The percentage of fetch, write, atomic, and other instructions that hit the data cache. Value range: 0% (no hit) to 100% (optimal).
type=gpa_float64
usage=percentage
[GLGfx8]
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TCC*_PERF_SEL_HIT[0..15]
TCC*_PERF_SEL_MISS[0..15]
eqn=0..15,sum16,0..15,sum16,16..31,sum16,+,/,(100),*

name=CacheMiss
desc=#GlobalMemory#The percentage of fetch, write, atomic, and other instructions that miss the data cache. Value range: 0% (optimal) to 100% (all miss).
type=gpa_float64
usage=percentage
[GLGfx8]
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TCC*_PERF_SEL_HIT[0..15]
TCC*_PERF_SEL_MISS[0..15]
eqn=16..31,sum16,0..15,sum16,16..31,sum16,+,/,(100),*

name=CacheHitCount
desc=#GlobalMemory#Count of fetch, write, atomic, and other instructions that hit the data cache.
type=gpa_float64
usage=items
[GLGfx8]
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TCC*_PERF_SEL_HIT[0..15]
eqn=0..15,sum16

name=CacheMissCount
desc=#GlobalMemory#Count of fetch, write, atomic, and other instructions that miss the data cache.
type=gpa_float64
usage=items
[GLGfx8]
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TCC*_PERF_SEL_MISS[0..15]
eqn=0..15,sum16

name=MemUnitBusy
desc=#GlobalMemory#The percentage of GPUTime the memory unit is active. The result includes the stall time (MemUnitStalled). This is measured with all extra fetches and writes and any cache or memory effects taken into account. Value range: 0% to 100% (fetch-bound).
type=gpa_float64
usage=percentage
[GLGfx8]
TA*_PERF_SEL_TA_BUSY[0..15]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0..15,max16,16,/,NUM_SHADER_ENGINES,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TA*_PERF_SEL_TA_BUSY[0..63]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0..63,max64,64,/,(100),*

name=MemUnitBusyCycles
desc=#GlobalMemory#Number of GPU cycles the memory unit is active. The result includes the stall time (MemUnitStalledCycles). This is measured with all extra fetches and writes and any cache or memory effects taken into account.
type=gpa_float64
usage=cycles
[GLGfx8]
TA*_PERF_SEL_TA_BUSY[0..15]
eqn=0..15,max16
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TA*_PERF_SEL_TA_BUSY[0..63]
eqn=0..63,max64

name=MemUnitStalled
desc=#GlobalMemory#The percentage of GPUTime the memory unit is stalled. Try reducing the number or size of fetches and writes if possible. Value range: 0% (optimal) to 100% (bad).
type=gpa_float64
usage=percentage
[GLGfx8]
TCP*_PERF_SEL_TCP_TA_DATA_STALL_CYCLES[0..15]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0..15,max16,16,/,NUM_SHADER_ENGINES,/,(100),*
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TCP*_PERF_SEL_TCP_TA_DATA_STALL_CYCLES[0..63]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0..63,max64,64,/,(100),*

name=MemUnitStalledCycles
desc=#GlobalMemory#Number of GPU cycles the memory unit is stalled.
type=gpa_float64
usage=cycles
[GLGfx8]
TCP*_PERF_SEL_TCP_TA_DATA_STALL_CYCLES[0..15]
eqn=0..15,max16
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TCP*_PERF_SEL_TCP_TA_DATA_STALL_CYCLES[0..63]
eqn=0..63,max64

name=WriteUnitStalled
desc=#GlobalMemory#The percentage of GPUTime the Write unit is stalled. Value range: 0% to 100% (bad).
type=gpa_float64
usage=percentage
[GLGfx8]
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TCC*_PERF_SEL_MC_WRREQ_STALL[0..15]
GRBM_PERF_SEL_GUI_ACTIVE
eqn=0..15,max16,16,/,(100),*

name=WriteUnitStalledCycles
desc=#GlobalMemory#Number of GPU cycles the Write unit is stalled.
type=gpa_float64
usage=cycles
[GLGfx8]
[DX11Gfx8]
[DX12Gfx8]
[VKGfx8]
TCC*_PERF_SEL_MC_WRREQ_STALL[0..15]
eqn=0..15,max16
